<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial de cuda on </title>
    <link>https://www.wikiod.com/pt/docs/cuda/</link>
    <description>Recent content in Tutorial de cuda on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/pt/docs/cuda/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Começando com cuda</title>
      <link>https://www.wikiod.com/pt/cuda/comecando-com-cuda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/pt/cuda/comecando-com-cuda/</guid>
      <description>Vamos lançar um único thread CUDA para dizer olá # Este simples programa CUDA demonstra como escrever uma função que será executada na GPU (também conhecida como &amp;ldquo;dispositivo&amp;rdquo;). A CPU, ou &amp;ldquo;host&amp;rdquo;, cria threads CUDA chamando funções especiais chamadas &amp;ldquo;kernels&amp;rdquo;. Os programas CUDA são programas C++ com sintaxe adicional.
Para ver como funciona, coloque o seguinte código em um arquivo chamado hello.cu:
#include &amp;lt;stdio.h&amp;gt; // __global__ functions, or &amp;quot;kernels&amp;quot;, execute on the device __global__ void hello_kernel(void) { printf(&amp;quot;Hello, world from the device!</description>
    </item>
    
    <item>
      <title>Redução paralela (por exemplo, como somar uma matriz)</title>
      <link>https://www.wikiod.com/pt/cuda/reducao-paralela-por-exemplo-como-somar-uma-matriz/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/pt/cuda/reducao-paralela-por-exemplo-como-somar-uma-matriz/</guid>
      <description>O algoritmo de redução paralela normalmente se refere a um algoritmo que combina uma matriz de elementos, produzindo um único resultado. Os problemas típicos que se enquadram nesta categoria são:
somando todos os elementos em uma matriz encontrar um máximo em uma matriz Em geral, a redução paralela pode ser aplicada para qualquer binário operador associativo, ou seja, (A*B)*C = A*(B*C). Com tal operador *, o algoritmo de redução paralela agrupa repetidamente os argumentos do array em pares.</description>
    </item>
    
    <item>
      <title>Comunicação entre blocos</title>
      <link>https://www.wikiod.com/pt/cuda/comunicacao-entre-blocos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/pt/cuda/comunicacao-entre-blocos/</guid>
      <description>Blocos em CUDA operam de forma semi-independente. Não há uma maneira segura de sincronizá-los todos. No entanto, isso não significa que eles não possam interagir uns com os outros de forma alguma.
Guarda do último bloco # Considere uma grade trabalhando em alguma tarefa, por exemplo. uma redução paralela. Inicialmente, cada bloco pode fazer seu trabalho de forma independente, produzindo algum resultado parcial. No final, no entanto, os resultados parciais precisam ser combinados e mesclados.</description>
    </item>
    
    <item>
      <title>Instalando o cuda</title>
      <link>https://www.wikiod.com/pt/cuda/instalando-o-cuda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/pt/cuda/instalando-o-cuda/</guid>
      <description>Para instalar o kit de ferramentas CUDA no Windows, primeiro você precisa instalar uma versão adequada do Visual Studio. O Visual Studio 2013 deve ser instalado se você for instalar o CUDA 7.0 ou 7.5. O Visual Studio 2015 tem suporte para CUDA 8.0 e posteriores.
Quando você tem uma versão adequada do VS em seu sistema, é hora de baixar e instalar o kit de ferramentas CUDA. Siga este link para encontrar a versão do kit de ferramentas CUDA que você está procurando: Arquivo do kit de ferramentas CUDA</description>
    </item>
    
  </channel>
</rss>
