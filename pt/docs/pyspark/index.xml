<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial do pyspark on </title>
    <link>https://www.wikiod.com/pt/docs/pyspark/</link>
    <description>Recent content in Tutorial do pyspark on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/pt/docs/pyspark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Introdução ao pyspark</title>
      <link>https://www.wikiod.com/pt/pyspark/introducao-ao-pyspark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/pt/pyspark/introducao-ao-pyspark/</guid>
      <description>Exemplo de contagem de palavras no Pyspark # O exemplo subjacente é apenas o fornecido na documentação oficial do pyspark. Clique aqui para acessar este exemplo.
# the first step involves reading the source text file from HDFS text_file = sc.textFile(&amp;quot;hdfs://...&amp;quot;) # this step involves the actual computation for reading the number of words in the file # flatmap, map and reduceByKey are all spark RDD functions counts = text_file.flatMap(lambda line: line.</description>
    </item>
    
  </channel>
</rss>
