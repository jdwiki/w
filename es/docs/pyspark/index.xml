<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial de pyspark on </title>
    <link>https://www.wikiod.com/es/docs/pyspark/</link>
    <description>Recent content in Tutorial de pyspark on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/es/docs/pyspark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Primeros pasos con pyspark</title>
      <link>https://www.wikiod.com/es/pyspark/primeros-pasos-con-pyspark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/pyspark/primeros-pasos-con-pyspark/</guid>
      <description>Conteo de palabras de muestra en Pyspark # El ejemplo subyacente es solo el que se proporciona en la documentación oficial de pyspark. Haga clic aquí para acceder a este ejemplo.
# the first step involves reading the source text file from HDFS text_file = sc.textFile(&amp;quot;hdfs://...&amp;quot;) # this step involves the actual computation for reading the number of words in the file # flatmap, map and reduceByKey are all spark RDD functions counts = text_file.</description>
    </item>
    
  </channel>
</rss>
