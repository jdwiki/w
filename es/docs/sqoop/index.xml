<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial de sqoop on </title>
    <link>https://www.wikiod.com/es/docs/sqoop/</link>
    <description>Recent content in Tutorial de sqoop on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/es/docs/sqoop/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Primeros pasos con sqoop</title>
      <link>https://www.wikiod.com/es/sqoop/primeros-pasos-con-sqoop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/sqoop/primeros-pasos-con-sqoop/</guid>
      <description>Instalación o configuración # Sqoop se envía como un paquete binario, sin embargo, está compuesto por dos partes separadas, cliente y servidor. You need to install server on single node in your cluster. This node will then serve as an entry point for all connecting Sqoop clients. Server acts as a mapreduce client and therefore Hadoop must be installed and configured on machine hosting Sqoop server. Clients can be installed on any arbitrary number of machines.</description>
    </item>
    
    <item>
      <title>Importación de Sqoop</title>
      <link>https://www.wikiod.com/es/sqoop/importacion-de-sqoop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/sqoop/importacion-de-sqoop/</guid>
      <description>Sintaxis # &amp;lt;rdbms-jdbc-url&amp;gt; // URL de RDBMS JDBC &amp;lt;username&amp;gt; // Nombre de usuario de la base de datos RDBMS &amp;lt;contraseña&amp;gt; // Contraseña de la base de datos RDBMS &amp;lt;nombre-tabla&amp;gt; // tabla de base de datos RDBMS &amp;lt;dirección de inicio de hdfs&amp;gt; // directorio de inicio de HDFS &amp;lt;condición&amp;gt; // Condición que se puede expresar en forma de consulta SQL con una cláusula WHERE. &amp;lt;consulta-sql&amp;gt; // Consulta SQL &amp;lt;target-dir&amp;gt; // Directorio de destino HDFS Sqoop es una herramienta de línea de comandos de Hadoop que importa tablas desde una fuente de datos RDBMS a HDFS y viceversa.</description>
    </item>
    
    <item>
      <title>Conexión de Sqoop a otras bases de datosalmacenes de datos</title>
      <link>https://www.wikiod.com/es/sqoop/conexion-de-sqoop-a-otras-bases-de-datosalmacenes-de-datos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/sqoop/conexion-de-sqoop-a-otras-bases-de-datosalmacenes-de-datos/</guid>
      <description>Muestra cómo se podría usar un script sqoop para importar datos de varios almacenes de datos/bases de datos.
Cargar controlador JDBC # Para acceder a la base de datos de MS SQL Server, Sqoop requiere un controlador JDBC adicional que se puede descargar de Microsoft. Los siguientes pasos instalarán el controlador JDBC de MSSQL Server en Sqoop:
wget &#39;http://download.microsoft.com/download/0/2/A/02AAE597-3865-456C-AE7F-613F99F850A8/sqljdbc_4.0.2206.100_enu.tar.gz&#39; tar -xvzf sqljdbc_4 cp sqljdbc_4.0/enu/sqljdbc4.jar /usr/hdp/current/sqoop-server/lib/ Validar la conexión # Para comprobar que la conexión con el servidor es válida:</description>
    </item>
    
    <item>
      <title>Exportación Sqoop</title>
      <link>https://www.wikiod.com/es/sqoop/exportacion-sqoop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/sqoop/exportacion-sqoop/</guid>
      <description>Ejemplo básico de exportación de Sqoop # La herramienta de exportación exporta un conjunto de archivos de HDFS a un RDBMS. La tabla de destino ya debe existir en la base de datos. Los archivos de entrada se leen y analizan en un conjunto de registros de acuerdo con los delimitadores especificados por el usuario.
Ejemplo :
sqoop export \ --connect=&amp;quot;jdbc:&amp;lt;databaseconnector&amp;gt;&amp;quot; \ --username=&amp;lt;username&amp;gt; \ --password=&amp;lt;password&amp;gt; \ --export-dir=&amp;lt;hdfs export directory&amp;gt; \ --table=&amp;lt;tablename&amp;gt; </description>
    </item>
    
    <item>
      <title>combine conjuntos de datos importados a través de la importación incremental usando Sqoop</title>
      <link>https://www.wikiod.com/es/sqoop/combine-conjuntos-de-datos-importados-a-traves-de-la-importacion-incremental-usando-sqoop/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/sqoop/combine-conjuntos-de-datos-importados-a-traves-de-la-importacion-incremental-usando-sqoop/</guid>
      <description>La importación incremental de Sqoop entra en escena debido a un fenómeno llamado CDC, es decir, Change Data Capture. Ahora, ¿qué es CDC?
CDC es un patrón de diseño que captura cambios de datos individuales en lugar de tratar con todos los datos. En lugar de volcar toda nuestra base de datos, usando CDC, podríamos capturar solo los cambios de datos realizados en la base de datos maestra.
Por ejemplo: si estamos lidiando con un problema de datos, digamos, 1 lakh de entradas de datos que ingresan al RDBMS diariamente y tenemos que obtener estos datos en Hadoop diariamente, entonces nos gustaría obtener los datos recién agregados, como importar los datos RDBMS completos diarios para Hadoop serán una sobrecarga y también retrasarán la disponibilidad de los datos.</description>
    </item>
    
  </channel>
</rss>
