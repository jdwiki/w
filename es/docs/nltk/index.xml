<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial on </title>
    <link>https://www.wikiod.com/es/docs/nltk/</link>
    <description>Recent content in Tutorial on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/es/docs/nltk/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Primeros pasos con nltk</title>
      <link>https://www.wikiod.com/es/nltk/primeros-pasos-con-nltk/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/nltk/primeros-pasos-con-nltk/</guid>
      <description>Función de descarga de NLTK # Puede instalar NLTK sobre pip (pip install nltk). Una vez instalado, muchos componentes no estarán presentes y no podrá utilizar algunas de las funciones de NLTK.
Desde su shell de Python, ejecute la función ntlk.download() para seleccionar qué paquetes adicionales desea instalar mediante la interfaz de usuario. Alternativamente, puede usar python -m nltk.downloader [nombre_del_paquete].
Para descargar todos los paquetes disponibles.
nltk.download(&amp;lsquo;all&amp;rsquo;)
Para descargar un paquete específico.</description>
    </item>
    
    <item>
      <title>Distribuciones de frecuencia</title>
      <link>https://www.wikiod.com/es/nltk/distribuciones-de-frecuencia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/nltk/distribuciones-de-frecuencia/</guid>
      <description>Este tema se centra en el uso de la clase nltk.FreqDist().
Distribución de frecuencias para contar las categorías léxicas más comunes # NLTK proporciona la clase FreqDist que nos permite calcular fácilmente una distribución de frecuencia dada una lista como entrada.
Aquí estamos usando una lista de etiquetas de parte del discurso (etiquetas POS) para ver qué categorías léxicas se usan más en el corpus marrón.
import nltk brown_tagged = nltk.</description>
    </item>
    
    <item>
      <title>Para las palabras</title>
      <link>https://www.wikiod.com/es/nltk/para-las-palabras/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/nltk/para-las-palabras/</guid>
      <description>Las palabras vacías son las palabras que se usan principalmente como relleno y apenas tienen un significado útil. Debemos evitar que estas palabras ocupen espacio en la base de datos o consuman un valioso tiempo de procesamiento. Podemos hacer fácilmente una lista de palabras para usarlas como palabras vacías y luego filtrar estas palabras de los datos que queremos procesar.
Filtrado de palabras vacías # NLTK tiene por defecto un montón de palabras que considera palabras vacías.</description>
    </item>
    
    <item>
      <title>Etiquetado POS</title>
      <link>https://www.wikiod.com/es/nltk/etiquetado-pos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/nltk/etiquetado-pos/</guid>
      <description>El etiquetado de partes del discurso crea tuplas de palabras y partes del discurso. Etiqueta palabras en una oración como sustantivos, adjetivos, verbos, etc. También puede etiquetar por tiempo, y más. Estas etiquetas significan lo que sea que significaron en sus datos de entrenamiento originales. Eres libre de inventar tus propias etiquetas en tus datos de entrenamiento, siempre que seas consistente en su uso. Los datos de entrenamiento generalmente requieren mucho trabajo para crearse, por lo que normalmente se usa un corpus preexistente.</description>
    </item>
    
    <item>
      <title>Tokenización</title>
      <link>https://www.wikiod.com/es/nltk/tokenizacion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/nltk/tokenizacion/</guid>
      <description>Se refiere a la división de oraciones y palabras del cuerpo del texto en tokens de oraciones o tokens de palabras, respectivamente. Es una parte esencial de NLP, ya que muchos módulos funcionan mejor (o solo) con etiquetas. Por ejemplo, pos_tag necesita tags como entrada y no las palabras, para etiquetarlas por partes del discurso.
Tokenización de oraciones y palabras del párrafo proporcionado por el usuario # from nltk.tokenize import sent_tokenize, word_tokenize example_text = input(&amp;quot;Enter the text: &amp;quot;) print(&amp;quot;Sentence Tokens:&amp;quot;) print(sent_tokenize(example_text)) print(&amp;quot;Word Tokens:&amp;quot;) print(word_tokenize(example_text)) </description>
    </item>
    
    <item>
      <title>derivación</title>
      <link>https://www.wikiod.com/es/nltk/derivacion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/nltk/derivacion/</guid>
      <description>Stemming es una especie de método de normalización. Muchas variaciones de palabras tienen el mismo significado, excepto cuando se trata de tiempo. La razón por la que derivamos es para acortar la búsqueda y normalizar las oraciones. Básicamente, es encontrar la raíz de las palabras después de eliminar el verbo y la parte del tiempo. Uno de los algoritmos de lematización más populares es el lematizador de Porter, que existe desde 1979.</description>
    </item>
    
  </channel>
</rss>
