<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cudaTutorial on </title>
    <link>https://www.wikiod.com/es/docs/cuda/</link>
    <description>Recent content in cudaTutorial on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/es/docs/cuda/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Comenzando con cuda</title>
      <link>https://www.wikiod.com/es/cuda/comenzando-con-cuda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/cuda/comenzando-con-cuda/</guid>
      <description>Iniciemos un solo hilo de CUDA para saludar # Este sencillo programa CUDA demuestra cómo escribir una función que se ejecutará en la GPU (también conocida como &amp;ldquo;dispositivo&amp;rdquo;). La CPU, o &amp;ldquo;host&amp;rdquo;, crea subprocesos CUDA llamando a funciones especiales llamadas &amp;ldquo;núcleos&amp;rdquo;. Los programas CUDA son programas C++ con sintaxis adicional.
Para ver cómo funciona, coloca el siguiente código en un archivo llamado hola.cu:
#include &amp;lt;stdio.h&amp;gt; // __global__ functions, or &amp;quot;kernels&amp;quot;, execute on the device __global__ void hello_kernel(void) { printf(&amp;quot;Hello, world from the device!</description>
    </item>
    
    <item>
      <title>Reducción paralela (por ejemplo, cómo sumar una matriz)</title>
      <link>https://www.wikiod.com/es/cuda/reduccion-paralela-por-ejemplo-como-sumar-una-matriz/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/cuda/reduccion-paralela-por-ejemplo-como-sumar-una-matriz/</guid>
      <description>El algoritmo de reducción paralela generalmente se refiere a un algoritmo que combina una matriz de elementos, produciendo un único resultado. Los problemas típicos que entran en esta categoría son:
resumir todos los elementos en una matriz encontrar un máximo en una matriz En general, la reducción paralela se puede aplicar para cualquier operador asociativo binario, es decir, (A*B)*C = A*(B*C). Con tal operador *, el algoritmo de reducción en paralelo agrupa repetidamente los argumentos de la matriz en pares.</description>
    </item>
    
    <item>
      <title>Comunicación entre bloques</title>
      <link>https://www.wikiod.com/es/cuda/comunicacion-entre-bloques/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/cuda/comunicacion-entre-bloques/</guid>
      <description>Los bloques en CUDA funcionan de forma semiindependiente. No existe una forma segura de sincronizarlos a todos. Sin embargo, eso no significa que no puedan interactuar entre sí de ninguna manera.
Guardia del último bloque # Considere una cuadrícula trabajando en alguna tarea, p. una reducción paralela. Inicialmente, cada bloque puede hacer su trabajo de forma independiente, produciendo algún resultado parcial. Sin embargo, al final, los resultados parciales deben combinarse y fusionarse.</description>
    </item>
    
    <item>
      <title>instalando cuda</title>
      <link>https://www.wikiod.com/es/cuda/instalando-cuda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/cuda/instalando-cuda/</guid>
      <description>Para instalar el kit de herramientas CUDA en Windows, primero debe instalar una versión adecuada de Visual Studio. Se debe instalar Visual Studio 2013 si va a instalar CUDA 7.0 o 7.5. Visual Studio 2015 es compatible con CUDA 8.0 y posteriores.
Cuando tenga una versión adecuada de VS en su sistema, es hora de descargar e instalar el kit de herramientas CUDA. Siga este enlace para encontrar la versión del kit de herramientas CUDA que está buscando: Archivo del kit de herramientas CUDA</description>
    </item>
    
  </channel>
</rss>
