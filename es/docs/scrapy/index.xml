<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial scrapy on </title>
    <link>https://www.wikiod.com/es/docs/scrapy/</link>
    <description>Recent content in Tutorial scrapy on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/es/docs/scrapy/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Empezando con scrapy</title>
      <link>https://www.wikiod.com/es/scrapy/empezando-con-scrapy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/scrapy/empezando-con-scrapy/</guid>
      <description>Instalación de Scrapy # requisito previo de la instalación scrapy:
Python 2.7 o superior 3.3 Paquetes pip y setuptools de Python. lxml OpenSSL. Puedes instalar Scrapy usando pip. Para instalar usando pip ejecute:
pip install Scrapy Instalación específica de la plataforma
Anaconda
Esta es la forma recomendada de instalar Scrapy.
Si ya tienes instalado Anaconda o Miniconda, la empresa Scrapinghub mantiene paquetes oficiales de conda para Linux, Windows y OS X.</description>
    </item>
    
    <item>
      <title>Conexión de scrapy a MySQL</title>
      <link>https://www.wikiod.com/es/scrapy/conexion-de-scrapy-a-mysql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/scrapy/conexion-de-scrapy-a-mysql/</guid>
      <description>Conexión e inserción masiva a MySQL en Scrapy usando el módulo MySQLDB - Python 2.7 # Este ejemplo demuestra cómo insertar datos dinámicamente en MySQL utilizando Python Scrapy.
No necesita editar el archivo pipelines.py para ningún proyecto.
Este ejemplo se puede utilizar para todo su proyecto.
Simplemente produzca you_data_dictionary desde su Spider y dentro de pipelines.py se creará una consulta automáticamente.
Las filas se insertan de forma masiva mediante la declaración de inserción masiva.</description>
    </item>
    
    <item>
      <title>Canalización de artículos</title>
      <link>https://www.wikiod.com/es/scrapy/canalizacion-de-articulos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/scrapy/canalizacion-de-articulos/</guid>
      <description>Forma de procesar cada elemento que genera Scrapy.
Una canalización de elementos es una clase de Python que anula algunos métodos específicos y debe activarse en la &amp;ldquo;configuración&amp;rdquo; del proyecto scrapy.
Creando una canalización dinámica en Python Scrapy # Habilite las canalizaciones en su settings.py
ITEM_PIPELINES = { &#39;project_folder.pipelines.MyPipeline&#39;: 100 } Luego escribe este código en items.py
# -*- coding: utf-8 -*- from scrapy import Item, Field from collections import OrderedDict class DynamicItem(Item): def __setitem__(self, key, value): self.</description>
    </item>
    
  </channel>
</rss>
