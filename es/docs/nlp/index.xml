<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial de PNL on </title>
    <link>https://www.wikiod.com/es/docs/nlp/</link>
    <description>Recent content in Tutorial de PNL on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/es/docs/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Empezando con la PNL</title>
      <link>https://www.wikiod.com/es/nlp/empezando-con-la-pnl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/nlp/empezando-con-la-pnl/</guid>
      <description>Programa básico de PNL de Stanford # Stanford CoreNLP es un conjunto de herramientas de procesamiento de lenguaje natural popular que admite muchas tareas básicas de NLP.
Para descargar e instalar el programa, descargue un paquete de lanzamiento e incluya los archivos *.jar necesarios en su classpath, o agregue la dependencia fuera de Maven central. Consulte la página de descarga para obtener más detalles. Por ejemplo:
curl http://nlp.stanford.edu/software/stanford-corenlp-full-2015-12-09.zip -o corenlp.zip unzip corenlp.</description>
    </item>
    
    <item>
      <title>Detección de límites de oraciones en Python</title>
      <link>https://www.wikiod.com/es/nlp/deteccion-de-limites-de-oraciones-en-python/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/nlp/deteccion-de-limites-de-oraciones-en-python/</guid>
      <description>Con Stanford CoreNLP, de Python # Primero debe ejecutar un servidor Stanford CoreNLP:
java -mx4g -cp &amp;quot;*&amp;quot; edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 50000 Aquí hay un fragmento de código que muestra cómo pasar datos al servidor Stanford CoreNLP, usando el paquete Python pycorenlp.
from pycorenlp import StanfordCoreNLP import pprint if __name__ == &#39;__main__&#39;: nlp = StanfordCoreNLP(&#39;http://localhost:9000&#39;) fp = open(&amp;quot;long_text.txt&amp;quot;) text = fp.read() output = nlp.annotate(text, properties={ &#39;annotators&#39;: &#39;tokenize,ssplit,pos,depparse,parse&#39;, &#39;outputFormat&#39;: &#39;json&#39; }) pp = pprint.</description>
    </item>
    
    <item>
      <title>OpenNLP</title>
      <link>https://www.wikiod.com/es/nlp/opennlp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/nlp/opennlp/</guid>
      <description>Sintaxis # opennlp SentenceDetector ./en-sent.bin &amp;lt; ./input.txt &amp;gt; salida.txt
Inicializar SentenceDetectorME así: SentenceDetectorME sentenciaDetector = new SentenceDetectorME(modelo);
Use el método &amp;lsquo;sentDetect&amp;rsquo; para obtener oraciones como esta: Cadena de oraciones[] = sentenciaDetector.sentDetect(&amp;ldquo;cadena de información&amp;rdquo;);
descargue modelos (como en-sent.bin) desde el siguiente [enlace] (http://opennlp.sourceforge.net/models-1.5/)
Detección de oraciones usando openNLP usando CLI y API de Java # usando CLI:
$ opennlp SentenceDetector ./en-sent.bin &amp;lt; ./input.txt &amp;gt; output.txt usando API:
import static java.nio.file.Files.readAllBytes; import static java.</description>
    </item>
    
    <item>
      <title>N-GRAMOS</title>
      <link>https://www.wikiod.com/es/nlp/n-gramos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/nlp/n-gramos/</guid>
      <description>Los N-GRAM son modelos estadísticos que predicen la siguiente palabra en la oración usando las n-1 palabras anteriores. Este tipo de modelos estadísticos que utilizan secuencias de palabras también se denominan modelos de lenguaje. Por ejemplo, tenemos una oración &amp;ldquo;No puedo leer sin mi lectura _____&amp;rdquo;, podemos decir que la siguiente palabra más probable sería &amp;ldquo;anteojos&amp;rdquo;. N-GRAMS predice la siguiente palabra en la secuencia usando la probabilidad condicional de la siguiente palabra.</description>
    </item>
    
  </channel>
</rss>
