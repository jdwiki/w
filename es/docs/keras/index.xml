<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial de Keras on </title>
    <link>https://www.wikiod.com/es/docs/keras/</link>
    <description>Recent content in Tutorial de Keras on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/es/docs/keras/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Primeros pasos con Keras</title>
      <link>https://www.wikiod.com/es/keras/primeros-pasos-con-keras/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/keras/primeros-pasos-con-keras/</guid>
      <description>Primeros pasos con Keras: 30 segundos # La estructura de datos central de Keras es un modelo, una forma de organizar capas. El principal tipo de modelo es el modelo Secuencial, una pila lineal de capas. Para arquitecturas más complejas, debe usar la API funcional de Keras.
Aquí está el modelo secuencial:
from keras.models import Sequential model = Sequential() Apilar capas es tan fácil como .add():
from keras.layers import Dense, Activation model.</description>
    </item>
    
    <item>
      <title>Manejo de grandes conjuntos de datos de entrenamiento con Keras fit_generator, generadores de Python y formato de archivo HDF5</title>
      <link>https://www.wikiod.com/es/keras/manejo-de-grandes-conjuntos-de-datos-de-entrenamiento-con-keras-fit_generator-generadores-de-python-y-formato-de-archivo-hdf5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/keras/manejo-de-grandes-conjuntos-de-datos-de-entrenamiento-con-keras-fit_generator-generadores-de-python-y-formato-de-archivo-hdf5/</guid>
      <description>Los problemas de aprendizaje automático a menudo requieren manejar grandes cantidades de datos de entrenamiento con recursos informáticos limitados, en particular la memoria. No siempre es posible cargar un conjunto de entrenamiento completo en la memoria. Afortunadamente, esto se puede solucionar mediante el uso del método fit_generator de Keras, los generadores de Python y el formato de archivo HDF5.
Este ejemplo asume que keras, numpy (como np) y h5py ya se han instalado e importado.</description>
    </item>
    
    <item>
      <title>Crear un modelo secuencial simple</title>
      <link>https://www.wikiod.com/es/keras/crear-un-modelo-secuencial-simple/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/keras/crear-un-modelo-secuencial-simple/</guid>
      <description>El modelo &amp;lsquo;secuencial&amp;rsquo; es una pila lineal de capas.
Perceptrón multicapa simple con modelos secuenciales # Puede crear un modelo secuencial pasando una lista de instancias de capa al constructor:
from keras.models import Sequential from keras.layers import Dense, Activation model = Sequential([ Dense(32, input_dim=784), Activation(&#39;relu&#39;), Dense(10), Activation(&#39;softmax&#39;), ]) También puede simplemente agregar capas mediante el método .add():
model = Sequential() model.add(Dense(32, input_dim=784)) model.add(Activation(&#39;relu&#39;)) Los modelos deben compilarse antes de su uso:</description>
    </item>
    
    <item>
      <title>Función de pérdida personalizada y métricas en Keras</title>
      <link>https://www.wikiod.com/es/keras/funcion-de-perdida-personalizada-y-metricas-en-keras/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/keras/funcion-de-perdida-personalizada-y-metricas-en-keras/</guid>
      <description>Puede crear una función de pérdida personalizada y métricas en Keras definiendo una función simbólica TensorFlow/Theano que devuelve un escalar para cada punto de datos y toma los siguientes dos argumentos: tensor de valores verdaderos, tensor de los valores predichos correspondientes.
Tenga en cuenta que la pérdida/métrica (para visualización y optimización) se calcula como la media de las pérdidas/métrica en todos los puntos de datos del lote.
Las funciones de pérdida de Keras se definen en losses.</description>
    </item>
    
    <item>
      <title>Clasificación de entradas espaciotemporales con CNN, RNN y MLP</title>
      <link>https://www.wikiod.com/es/keras/clasificacion-de-entradas-espaciotemporales-con-cnn-rnn-y-mlp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/keras/clasificacion-de-entradas-espaciotemporales-con-cnn-rnn-y-mlp/</guid>
      <description>Los datos espaciotemporales, o datos con cualidades espaciales y temporales, son una ocurrencia común. Los ejemplos incluyen videos, así como secuencias de datos similares a imágenes, como espectrogramas.
Las redes neuronales convolucionales (CNN) son particularmente adecuadas para encontrar patrones espaciales. Las redes neuronales recurrentes (RNN), por otro lado, son particularmente adecuadas para encontrar patrones temporales. Estos dos, en combinación con los perceptrones multicapa, pueden ser efectivos para clasificar entradas espaciotemporales.</description>
    </item>
    
    <item>
      <title>Transferencia de aprendizaje y ajuste fino con Keras</title>
      <link>https://www.wikiod.com/es/keras/transferencia-de-aprendizaje-y-ajuste-fino-con-keras/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/es/keras/transferencia-de-aprendizaje-y-ajuste-fino-con-keras/</guid>
      <description>Este tema incluye ejemplos breves, breves pero completos de cómo cargar pesas preentrenadas, insertar nuevas capas encima o en medio de las preentrenadas y entrenar una nueva red con pesas parcialmente preentrenadas. Se requiere un ejemplo para cada una de las redes preentrenadas listas para usar, disponibles en la biblioteca Keras (VGG, ResNet, Inception, Xception, MobileNet).
Transferir aprendizaje usando Keras y VGG # En este ejemplo, se presentan tres subejemplos breves y completos:</description>
    </item>
    
  </channel>
</rss>
