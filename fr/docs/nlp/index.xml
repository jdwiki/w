<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutoriel pnl on </title>
    <link>https://www.wikiod.com/fr/docs/nlp/</link>
    <description>Recent content in Tutoriel pnl on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/fr/docs/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Débuter avec la PNL</title>
      <link>https://www.wikiod.com/fr/nlp/debuter-avec-la-pnl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/nlp/debuter-avec-la-pnl/</guid>
      <description>Stanford CorePNL # Stanford CoreNLP est une boîte à outils populaire de traitement du langage naturel prenant en charge de nombreuses tâches NLP de base.
Pour télécharger et installer le programme, téléchargez un package de version et incluez les fichiers *.jar nécessaires dans votre chemin de classe, ou ajoutez la dépendance hors de Maven central. Voir la page de téléchargement pour plus de détails. Par exemple:
curl http://nlp.stanford.edu/software/stanford-corenlp-full-2015-12-09.zip -o corenlp.zip unzip corenlp.</description>
    </item>
    
    <item>
      <title>Détection des limites de phrase en Python</title>
      <link>https://www.wikiod.com/fr/nlp/detection-des-limites-de-phrase-en-python/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/nlp/detection-des-limites-de-phrase-en-python/</guid>
      <description>Avec Stanford CoreNLP, de Python # Vous devez d&amp;rsquo;abord exécuter un serveur Stanford CoreNLP :
java -mx4g -cp &amp;quot;*&amp;quot; edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 50000 Voici un extrait de code montrant comment transmettre des données au serveur Stanford CoreNLP, à l&amp;rsquo;aide du package Python &amp;ldquo;pycorenlp&amp;rdquo;.
from pycorenlp import StanfordCoreNLP import pprint if __name__ == &#39;__main__&#39;: nlp = StanfordCoreNLP(&#39;http://localhost:9000&#39;) fp = open(&amp;quot;long_text.txt&amp;quot;) text = fp.read() output = nlp.annotate(text, properties={ &#39;annotators&#39;: &#39;tokenize,ssplit,pos,depparse,parse&#39;, &#39;outputFormat&#39;: &#39;json&#39; }) pp = pprint.</description>
    </item>
    
    <item>
      <title>OpenNLP</title>
      <link>https://www.wikiod.com/fr/nlp/opennlp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/nlp/opennlp/</guid>
      <description>Syntaxe # opennlp SentenceDetector ./en-sent.bin &amp;lt; ./input.txt &amp;gt; output.txt
Initialisez SentenceDetectorME comme ceci : SentenceDetectorME sentenceDetector = new SentenceDetectorME(model);
Utilisez la méthode ‘sentDetect’ pour obtenir des phrases comme celle-ci : String sentences[] = sentenceDetector.sentDetect(&amp;ldquo;string of information&amp;rdquo;);
télécharger des modèles (comme en-sent.bin) à partir du [lien] suivant (http://opennlp.sourceforge.net/models-1.5/)
Détection de phrases à l&amp;rsquo;aide d&amp;rsquo;openNLP à l&amp;rsquo;aide de la CLI et de l&amp;rsquo;API Java # à l&amp;rsquo;aide de la CLI :
$ opennlp SentenceDetector .</description>
    </item>
    
    <item>
      <title>N-GRAMMES</title>
      <link>https://www.wikiod.com/fr/nlp/n-grammes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/nlp/n-grammes/</guid>
      <description>Les N-GRAM sont des modèles statistiques qui prédisent le mot suivant dans la phrase en utilisant les n-1 mots précédents. Ce type de modèles statistiques qui utilisent des séquences de mots sont également appelés modèles de langage. Par exemple, nous avons une phrase &amp;ldquo;Je ne peux pas lire sans lire _____&amp;rdquo;, nous pouvons dire que le prochain mot le plus probable serait &amp;ldquo;lunettes&amp;rdquo;. N-GRAMS prédit le mot suivant dans la séquence en utilisant la probabilité conditionnelle du mot suivant.</description>
    </item>
    
  </channel>
</rss>
