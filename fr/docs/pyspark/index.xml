<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutoriel pyspark on </title>
    <link>https://www.wikiod.com/fr/docs/pyspark/</link>
    <description>Recent content in Tutoriel pyspark on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/fr/docs/pyspark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Premiers pas avec pyspark</title>
      <link>https://www.wikiod.com/fr/pyspark/premiers-pas-avec-pyspark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/pyspark/premiers-pas-avec-pyspark/</guid>
      <description>Exemple de nombre de mots dans Pyspark # L&amp;rsquo;exemple sous-jacent est juste celui donné dans la documentation officielle de pyspark. Veuillez cliquer [ici][1] pour accéder à cet exemple.
[1] : http://spark.apache.org/examples.html
# the first step involves reading the source text file from HDFS text_file = sc.textFile(&amp;quot;hdfs://...&amp;quot;) # this step involves the actual computation for reading the number of words in the file # flatmap, map and reduceByKey are all spark RDD functions counts = text_file.</description>
    </item>
    
  </channel>
</rss>
