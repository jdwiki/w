<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutoriel d&#39;apprentissage automatique on </title>
    <link>https://www.wikiod.com/fr/docs/machine-learning/</link>
    <description>Recent content in Tutoriel d&#39;apprentissage automatique on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/fr/docs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Premiers pas avec l&#39;apprentissage automatique</title>
      <link>https://www.wikiod.com/fr/machine-learning/premiers-pas-avec-lapprentissage-automatique/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/machine-learning/premiers-pas-avec-lapprentissage-automatique/</guid>
      <description>Installation ou configuration à l&amp;rsquo;aide de Python # 1) scikit apprendre
scikit-learn est un module Python pour l&amp;rsquo;apprentissage automatique construit sur SciPy et distribué sous la licence BSD à 3 clauses. Il comporte divers algorithmes de classification, de régression et de clustering, notamment des machines vectorielles de support, des forêts aléatoires, l&amp;rsquo;amplification de gradient, k-means et DBSCAN, et est conçu pour interagir avec les bibliothèques numériques et scientifiques Python NumPy et SciPy.</description>
    </item>
    
    <item>
      <title>Perceptron</title>
      <link>https://www.wikiod.com/fr/machine-learning/perceptron/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/machine-learning/perceptron/</guid>
      <description>Implémentation d&amp;rsquo;un modèle Perceptron en C++ # Dans cet exemple, je vais passer en revue l&amp;rsquo;implémentation du modèle perceptron en C++ afin que vous puissiez avoir une meilleure idée de son fonctionnement.
Tout d&amp;rsquo;abord, c&amp;rsquo;est une bonne pratique d&amp;rsquo;écrire un algorithme simple de ce que nous voulons faire.
Algorithme:
Créez un vecteur pour les poids et initialisez-le à 0 (n&amp;rsquo;oubliez pas d&amp;rsquo;ajouter le terme de biais) Continuez à ajuster les pondérations jusqu&amp;rsquo;à ce que nous obtenions 0 erreur ou un faible nombre d&amp;rsquo;erreurs.</description>
    </item>
    
    <item>
      <title>Enseignement supervisé</title>
      <link>https://www.wikiod.com/fr/machine-learning/enseignement-supervise/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/machine-learning/enseignement-supervise/</guid>
      <description>Régression linéaire # Étant donné que l&amp;rsquo;apprentissage supervisé consiste en une cible ou une variable de résultat (ou une variable dépendante) qui doit être prédite à partir d&amp;rsquo;un ensemble donné de prédicteurs (variables indépendantes). En utilisant cet ensemble de variables, nous générons une fonction qui mappe les entrées aux sorties souhaitées. Le processus d&amp;rsquo;apprentissage se poursuit jusqu&amp;rsquo;à ce que le modèle atteigne un niveau de précision souhaité sur les données d&amp;rsquo;apprentissage.</description>
    </item>
    
    <item>
      <title>Les réseaux de neurones</title>
      <link>https://www.wikiod.com/fr/machine-learning/les-reseaux-de-neurones/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/machine-learning/les-reseaux-de-neurones/</guid>
      <description>Fonctions d&amp;rsquo;activation # Les fonctions d&amp;rsquo;activation, également appelées fonction de transfert, sont utilisées pour mapper les nœuds d&amp;rsquo;entrée sur les nœuds de sortie d&amp;rsquo;une certaine manière.
Ils sont utilisés pour conférer une non linéarité à la sortie d&amp;rsquo;une couche de réseau neuronal.
Certaines fonctions couramment utilisées et leurs courbes sont données ci-dessous : [![Fonctions d&amp;rsquo;activation][1]][1]
Fonction sigmoïde # Le sigmoïde est une fonction d&amp;rsquo;écrasement dont la sortie est dans la plage [0, 1].</description>
    </item>
    
    <item>
      <title>Métriques d&#39;évaluation</title>
      <link>https://www.wikiod.com/fr/machine-learning/metriques-devaluation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/machine-learning/metriques-devaluation/</guid>
      <description>Zone sous la courbe de la caractéristique de fonctionnement du récepteur (AUROC) # L&amp;rsquo;AUROC est l&amp;rsquo;une des métriques les plus couramment utilisées pour évaluer les performances d&amp;rsquo;un classifieur. Cette section explique comment le calculer.
AUC (Area Under the Curve) est utilisé la plupart du temps pour signifier AUROC, ce qui est une mauvaise pratique car AUC est ambigu (il peut s&amp;rsquo;agir de n&amp;rsquo;importe quelle courbe) alors qu&amp;rsquo;AUROC ne l&amp;rsquo;est pas.</description>
    </item>
    
    <item>
      <title>Apprentissage automatique à l&#39;aide de Java</title>
      <link>https://www.wikiod.com/fr/machine-learning/apprentissage-automatique-a-laide-de-java/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/machine-learning/apprentissage-automatique-a-laide-de-java/</guid>
      <description>liste d&amp;rsquo;outils # Cortical.io - Retina: an API performing complex NLP operations (disambiguation, classification, streaming text filtering, etc...) as quickly and intuitively as the brain. CoreNLP - Stanford CoreNLP provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words Stanford Parser - A natural language parser is a program that works out the grammatical structure of sentences Stanford POS Tagger - A Part-Of-Speech Tagger (POS Tagger Stanford Name Entity Recognizer - Stanford NER is a Java implementation of a Named Entity Recognizer.</description>
    </item>
    
    <item>
      <title>L&#39;apprentissage en profondeur</title>
      <link>https://www.wikiod.com/fr/machine-learning/lapprentissage-en-profondeur/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/machine-learning/lapprentissage-en-profondeur/</guid>
      <description>L&amp;rsquo;apprentissage en profondeur est un sous-domaine de l&amp;rsquo;apprentissage automatique où les réseaux de neurones artificiels multicouches sont utilisés à des fins d&amp;rsquo;apprentissage. Deep Learning a trouvé de nombreuses implémentations intéressantes, par ex. Reconnaissance vocale, sous-titres sur Youtube, recommandation Amazon, etc. Pour plus d&amp;rsquo;informations, il existe un sujet dédié à [l&amp;rsquo;apprentissage en profondeur] (https://www.wikiod.com/fr/deep-learning).
Brève brève de l&amp;rsquo;apprentissage en profondeur # Pour former un réseau de neurones, nous devons d&amp;rsquo;abord concevoir une idée bonne et efficace.</description>
    </item>
    
    <item>
      <title>Scikit Apprendre</title>
      <link>https://www.wikiod.com/fr/machine-learning/scikit-apprendre/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/machine-learning/scikit-apprendre/</guid>
      <description>Un problème de classification simple de base (XOR) utilisant k algorithme du plus proche voisin # Considérez que vous voulez prédire la bonne réponse pour le problème populaire XOR. Vous saviez ce qu&amp;rsquo;est XOR (par exemple [x0 x1] =&amp;gt; y). par exemple [0 0] =&amp;gt; 0, [0 1] =&amp;gt; [1] et&amp;hellip;
#Load Sickit learn data from sklearn.neighbors import KNeighborsClassifier #X is feature vectors, and y is correct label(To train model) X = [[0, 0],[0 ,1],[1, 0],[1, 1]] y = [0,1,1,0] #Initialize a Kneighbors Classifier with K parameter set to 2 KNC = KNeighborsClassifier(n_neighbors= 2) #Fit the model(the KNC learn y Given X) KNC.</description>
    </item>
    
    <item>
      <title>SVM</title>
      <link>https://www.wikiod.com/fr/machine-learning/svm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/machine-learning/svm/</guid>
      <description>Différence entre régression logistique et SVM # Limite de décision lorsque nous classons à l&amp;rsquo;aide de la régression logistique- [![Régression logistique][1]][1]
Limite de décision lorsque nous classons à l&amp;rsquo;aide de SVM-
[![Classification à l&amp;rsquo;aide de SVM][2]][2]
Comme on peut l&amp;rsquo;observer, SVM essaie de maintenir un « écart » de chaque côté de la frontière de décision. Cela s&amp;rsquo;avère utile lorsque nous rencontrons de nouvelles données.
Avec de nouvelles données-
La régression logistique fonctionne ** mal ** (le nouveau cercle rouge est classé comme bleu) -</description>
    </item>
    
    <item>
      <title>L&#39;apprentissage automatique et sa classification</title>
      <link>https://www.wikiod.com/fr/machine-learning/lapprentissage-automatique-et-sa-classification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/machine-learning/lapprentissage-automatique-et-sa-classification/</guid>
      <description>Qu&amp;rsquo;est-ce que l&amp;rsquo;apprentissage automatique ? # Deux définitions du Machine Learning sont proposées. Arthur Samuel l&amp;rsquo;a décrit comme suit :
le domaine d&amp;rsquo;étude qui donne aux ordinateurs la capacité d&amp;rsquo;apprendre sans étant explicitement programmé.
Il s&amp;rsquo;agit d&amp;rsquo;une ancienne définition informelle.
Tom Mitchell propose une définition plus moderne :
On dit qu&amp;rsquo;un programme informatique apprend de l&amp;rsquo;expérience E par rapport à une classe de tâches T et une mesure de performance P, si sa performance à les tâches en T, mesurées par P, s&amp;rsquo;améliorent avec l&amp;rsquo;expérience E.</description>
    </item>
    
  </channel>
</rss>
