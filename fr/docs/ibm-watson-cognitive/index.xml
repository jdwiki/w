<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutoriel ibm-watson-cognitive on </title>
    <link>https://www.wikiod.com/fr/docs/ibm-watson-cognitive/</link>
    <description>Recent content in Tutoriel ibm-watson-cognitive on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/fr/docs/ibm-watson-cognitive/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Premiers pas avec ibm-watson-cognitive</title>
      <link>https://www.wikiod.com/fr/ibm-watson-cognitive/premiers-pas-avec-ibm-watson-cognitive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/ibm-watson-cognitive/premiers-pas-avec-ibm-watson-cognitive/</guid>
      <description>Obtention des informations d&amp;rsquo;identification de l&amp;rsquo;API # Pour vous authentifier auprès des services Watson, vous avez besoin d&amp;rsquo;informations d&amp;rsquo;identification pour chaque service que vous prévoyez d&amp;rsquo;utiliser. Selon le service, vous devrez transmettre un nom d&amp;rsquo;utilisateur et un mot de passe avec l&amp;rsquo;authentification de base, ou vous devrez transmettre une clé API dans un paramètre pour chaque demande que vous effectuez.
Comment obtenir des informations d&amp;rsquo;identification pour un service Watson :</description>
    </item>
    
    <item>
      <title>Discours au texte</title>
      <link>https://www.wikiod.com/fr/ibm-watson-cognitive/discours-au-texte/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/ibm-watson-cognitive/discours-au-texte/</guid>
      <description>IBM Watson Speech to Text offre une variété d&amp;rsquo;options pour la transcription audio dans différentes langues et formats :
WebSockets - établit une connexion persistante via le protocole WebSocket pour une transcription continue - Sessionless : transcrivez l&amp;rsquo;audio sans avoir à établir et maintenir une session
Sessions : créez de longs échanges multitours avec le service ou établissez plusieurs conversations parallèles avec une instance particulière du service - Asynchrone : fournit une interface HTTP non bloquante pour la transcription audio.</description>
    </item>
    
    <item>
      <title>AlchimieLangage</title>
      <link>https://www.wikiod.com/fr/ibm-watson-cognitive/alchimielangage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/ibm-watson-cognitive/alchimielangage/</guid>
      <description>AlchemyLanguage est une collection de méthodes d&amp;rsquo;analyse de texte qui fournissent un aperçu plus approfondi de votre texte ou de votre contenu HTML. Consultez la rubrique [Getting Started][1] pour savoir comment démarrer avec AlchemyLanguage et d&amp;rsquo;autres services Watson. Pour plus de détails et d&amp;rsquo;exemples sur AlchemyLanguage, consultez la [référence API][2] et la [documentation][3].
Limites de taille # Contenu HTML avant nettoyage du texte : 600 Ko Texte source, après nettoyage du texte : 50 Ko Appels utilisant des modèles personnalisés : 5 Ko Support linguistique # Pour voir quelles langues sont prises en charge pour chaque fonction, reportez-vous à l&amp;rsquo;entrée de chaque fonction dans la [référence API][4].</description>
    </item>
    
    <item>
      <title>Reconnaissance visuelle</title>
      <link>https://www.wikiod.com/fr/ibm-watson-cognitive/reconnaissance-visuelle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/ibm-watson-cognitive/reconnaissance-visuelle/</guid>
      <description>Obtenir une liste de classificateurs personnalisés # Cela répertorie tous les classificateurs personnalisés que vous avez formés.
&#39;use strict&#39;; let watson = require(&#39;watson-developer-cloud&#39;); var visualRecognition = watson.visual_recognition({ version: &#39;v3&#39;, api_key: process.env[&#39;API_KEY&#39;], version_date:&#39;2016-05-19&#39; }); let url = &amp;quot;https://upload.wikimedia.org/wikipedia/commons/1/1c/Chris_Evans_filming_Captain_America_in_DC_cropped.jpg&amp;quot; visualRecognition.classify({url: url}, function(error, results) { console.log(JSON.stringify(results,null,2)); }); Obtenir des informations sur un classificateur personnalisé spécifique # Cela renvoie des informations sur un ID de classificateur spécifique que vous avez formé. Cela inclut des informations sur son état actuel (c&amp;rsquo;est-à-dire s&amp;rsquo;il est prêt ou non).</description>
    </item>
    
    <item>
      <title>Récupérer et classer</title>
      <link>https://www.wikiod.com/fr/ibm-watson-cognitive/recuperer-et-classer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/ibm-watson-cognitive/recuperer-et-classer/</guid>
      <description>Le client Solrj et le SDK Java sont indépendants, vous pouvez donc les mettre à jour individuellement. Assurez-vous toujours d&amp;rsquo;utiliser la dernière version du SDK Java.
Consultez la page de publication de GitHub pour les mises à jour https://github.com/watson-developer-cloud/java-sdk/releases
Recherche et classement à l&amp;rsquo;aide de Retrieve and Rank en Java # Installez les dépendances requises :
&#39;org.apache.solr:solr-solrj:5.5.1&#39; &#39;org.apache.httpcomponents:httpclient:4.3.6&#39; &#39;com.ibm.watson.developer_cloud:java-sdk:3.2.0&#39; Le code ci-dessous suppose que vous avez une collection Solr avec des documents et que vous avez formé un classeur, sinon suivez ce [tutoriel][1]</description>
    </item>
    
  </channel>
</rss>
