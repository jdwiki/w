<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutoriel tensorflow on </title>
    <link>https://www.wikiod.com/fr/docs/tensorflow/</link>
    <description>Recent content in Tutoriel tensorflow on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/fr/docs/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Premiers pas avec tensorflow</title>
      <link>https://www.wikiod.com/fr/tensorflow/premiers-pas-avec-tensorflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/tensorflow/premiers-pas-avec-tensorflow/</guid>
      <description>Exemple de base # Tensorflow est plus qu&amp;rsquo;un simple cadre d&amp;rsquo;apprentissage en profondeur. C&amp;rsquo;est un cadre de calcul général pour effectuer des opérations mathématiques générales de manière parallèle et distribuée. Un exemple de ce type est décrit ci-dessous.
Régression linéaire # Un exemple statistique de base couramment utilisé et assez simple à calculer consiste à ajuster une ligne à un ensemble de données. La méthode pour le faire dans tensorflow est décrite ci-dessous dans le code et les commentaires.</description>
    </item>
    
    <item>
      <title>Utilisation de la convolution 1D</title>
      <link>https://www.wikiod.com/fr/tensorflow/utilisation-de-la-convolution-1d/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/tensorflow/utilisation-de-la-convolution-1d/</guid>
      <description>Exemple de base # Mise à jour : TensorFlow prend désormais en charge la convolution 1D depuis la version r0.11, en utilisant [tf.nn.conv1d](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn. html#conv1d).
Prenons un exemple de base avec une entrée de longueur &amp;ldquo;10&amp;rdquo; et de dimension &amp;ldquo;16&amp;rdquo;. La taille du lot est &amp;lsquo;32&amp;rsquo;. Nous avons donc un espace réservé avec la forme d&amp;rsquo;entrée [batch_size, 10, 16].
batch_size = 32 x = tf.placeholder(tf.float32, [batch_size, 10, 16]) Nous créons ensuite un filtre de largeur 3, et nous prenons &amp;lsquo;16&amp;rsquo; canaux en entrée, et sortons également &amp;lsquo;16&amp;rsquo; canaux.</description>
    </item>
    
    <item>
      <title>Comment utiliser les collections de graphes TensorFlow ?</title>
      <link>https://www.wikiod.com/fr/tensorflow/comment-utiliser-les-collections-de-graphes-tensorflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/tensorflow/comment-utiliser-les-collections-de-graphes-tensorflow/</guid>
      <description>Lorsque vous avez un modèle énorme, il est utile de former des groupes de tenseurs dans votre graphe de calcul, qui sont connectés les uns aux autres. Par exemple, la classe tf.GraphKeys contient des collections standard telles que :
tf.GraphKeys.VARIABLES tf.GraphKeys.TRAINABLE_VARIABLES tf.GraphKeys.SUMMARIES Créez votre propre collection et utilisez-la pour collecter toutes vos pertes. # Ici, nous allons créer une collection pour les pertes du graphe de calcul de Neural Network.</description>
    </item>
    
    <item>
      <title>Enregistrer et restaurer un modèle dans TensorFlow</title>
      <link>https://www.wikiod.com/fr/tensorflow/enregistrer-et-restaurer-un-modele-dans-tensorflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/tensorflow/enregistrer-et-restaurer-un-modele-dans-tensorflow/</guid>
      <description>Tensorflow fait la distinction entre la sauvegarde/restauration des valeurs actuelles de toutes les variables d&amp;rsquo;un graphique et la sauvegarde/restauration de la structure réelle du graphique. Pour restaurer le graphique, vous êtes libre d&amp;rsquo;utiliser les fonctions de Tensorflow ou simplement d&amp;rsquo;appeler à nouveau votre morceau de code, qui a construit le graphique en premier lieu. Lors de la définition du graphique, vous devez également réfléchir à quelles variables/opérations doivent être récupérables une fois le graphique enregistré et restauré.</description>
    </item>
    
    <item>
      <title>Créer des RNN, des LSTM et des RNNLSTM bidirectionnels avec TensorFlow</title>
      <link>https://www.wikiod.com/fr/tensorflow/creer-des-rnn-des-lstm-et-des-rnnlstm-bidirectionnels-avec-tensorflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/tensorflow/creer-des-rnn-des-lstm-et-des-rnnlstm-bidirectionnels-avec-tensorflow/</guid>
      <description>Création d&amp;rsquo;un LSTM bidirectionnel # import tensorflow as tf dims, layers = 32, 2 # Creating the forward and backwards cells lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(dims, forget_bias=1.0) lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(dims, forget_bias=1.0) # Pass lstm_fw_cell / lstm_bw_cell directly to tf.nn.bidrectional_rnn # if only a single layer is needed lstm_fw_multicell = tf.nn.rnn_cell.MultiRNNCell([lstm_fw_cell]*layers) lstm_bw_multicell = tf.nn.rnn_cell.MultiRNNCell([lstm_bw_cell]*layers) # tf.nn.bidirectional_rnn takes a list of tensors with shape # [batch_size x cell_fw.state_size], so separate the input into discrete # timesteps.</description>
    </item>
    
    <item>
      <title>Utilisation de la normalisation par lots</title>
      <link>https://www.wikiod.com/fr/tensorflow/utilisation-de-la-normalisation-par-lots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/tensorflow/utilisation-de-la-normalisation-par-lots/</guid>
      <description>Paramètres # Paramètres contrib.layers.batch_norm Remarques bêta type python &amp;ldquo;bool&amp;rdquo;. Centrer ou non moving_mean et moving_variance &amp;mdash;&amp;mdash; &amp;mdash;&amp;mdash; gamma type python &amp;ldquo;bool&amp;rdquo;. S&amp;rsquo;il faut ou non mettre à l&amp;rsquo;échelle moving_mean et moving_variance &amp;mdash;&amp;mdash; &amp;mdash;&amp;mdash; is_training Accepte python bool ou TensorFlow tf.palceholder(tf.bool) &amp;mdash;&amp;mdash; &amp;mdash;&amp;mdash; pourriture Le paramètre par défaut est decay=0.999. Une valeur plus petite (c&amp;rsquo;est-à-dire &amp;ldquo;décroissance = 0,9&amp;rdquo;) est préférable pour un ensemble de données plus petit et/ou moins d&amp;rsquo;étapes d&amp;rsquo;apprentissage. Voici une capture d&amp;rsquo;écran du résultat de l&amp;rsquo;exemple de travail ci-dessus.</description>
    </item>
    
    <item>
      <title>Utilisation de la condition if dans le graphique TensorFlow avec tf.cond</title>
      <link>https://www.wikiod.com/fr/tensorflow/utilisation-de-la-condition-if-dans-le-graphique-tensorflow-avec-tfcond/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/tensorflow/utilisation-de-la-condition-if-dans-le-graphique-tensorflow-avec-tfcond/</guid>
      <description>Paramètres # Paramètre Détails préd un tenseur TensorFlow de type bool fn1 une fonction appelable, sans argument fn2 une fonction appelable, sans argument nom (facultatif) nom de l&amp;rsquo;opération pred ne peut pas être simplement True ou False, il doit s&amp;rsquo;agir d&amp;rsquo;un tenseur Les fonctions fn1 et fn2 doivent renvoyer le même nombre de sorties, avec les mêmes types. Exemple de base # x = tf.constant(1.) bool = tf.constant(True) res = tf.</description>
    </item>
    
    <item>
      <title>Comment déboguer une fuite de mémoire dans TensorFlow</title>
      <link>https://www.wikiod.com/fr/tensorflow/comment-deboguer-une-fuite-de-memoire-dans-tensorflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/tensorflow/comment-deboguer-une-fuite-de-memoire-dans-tensorflow/</guid>
      <description>Utilisez Graph.finalize() pour intercepter les nœuds ajoutés au graphique # Le mode d&amp;rsquo;utilisation le plus courant de TensorFlow consiste d&amp;rsquo;abord à construire un graphe de flux de données d&amp;rsquo;opérateurs TensorFlow (comme tf.constant() et tf.matmul(), puis à exécuter les étapes en appelant le [ tf.Session.run()][1] méthode dans une boucle (par exemple une boucle d&amp;rsquo;entraînement).
Une source courante de fuites de mémoire est l&amp;rsquo;endroit où la boucle d&amp;rsquo;apprentissage contient des appels qui ajoutent des nœuds au graphe, et ceux-ci s&amp;rsquo;exécutent à chaque itération, provoquant la croissance du graphe.</description>
    </item>
    
    <item>
      <title>Mesurer le temps d&#39;exécution des opérations individuelles</title>
      <link>https://www.wikiod.com/fr/tensorflow/mesurer-le-temps-dexecution-des-operations-individuelles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/tensorflow/mesurer-le-temps-dexecution-des-operations-individuelles/</guid>
      <description>Exemple de base avec l&amp;rsquo;objet Timeline de TensorFlow # L&amp;rsquo;objet [Timeline][2] permet d&amp;rsquo;obtenir le temps d&amp;rsquo;exécution de chaque nœud du graphe :
vous utilisez un sess.run() classique mais spécifiez également les arguments optionnels options et run_metadata vous créez ensuite un objet Timeline avec les données run_metadata.step_stats Voici un exemple de programme qui mesure les performances d&amp;rsquo;une multiplication matricielle :
import tensorflow as tf from tensorflow.python.client import timeline x = tf.random_normal([1000, 1000]) y = tf.</description>
    </item>
    
    <item>
      <title>Lire les données</title>
      <link>https://www.wikiod.com/fr/tensorflow/lire-les-donnees/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/fr/tensorflow/lire-les-donnees/</guid>
      <description>Comment charger des images et des étiquettes à partir d&amp;rsquo;un fichier TXT # Il n&amp;rsquo;a pas été expliqué dans la documentation Tensorflow comment charger des images et des étiquettes directement à partir d&amp;rsquo;un fichier TXT. Le code ci-dessous illustre comment je l&amp;rsquo;ai réalisé. Cependant, cela ne signifie pas que c&amp;rsquo;est la meilleure façon de le faire et que cela aidera dans les étapes suivantes.
Par exemple, je charge les étiquettes dans une seule valeur entière {0,1} alors que la documentation utilise un vecteur à chaud [0,1].</description>
    </item>
    
  </channel>
</rss>
