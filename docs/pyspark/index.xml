<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pyspark Tutorial on </title>
    <link>https://www.wikiod.com/docs/pyspark/</link>
    <description>Recent content in pyspark Tutorial on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/docs/pyspark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Getting started with pyspark</title>
      <link>https://www.wikiod.com/pyspark/getting-started-with-pyspark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/pyspark/getting-started-with-pyspark/</guid>
      <description>Sample Word Count in Pyspark # The underlying example is just the one given in the official pyspark documentation. Please click here to reach this example.
# the first step involves reading the source text file from HDFS text_file = sc.textFile(&amp;quot;hdfs://...&amp;quot;) # this step involves the actual computation for reading the number of words in the file # flatmap, map and reduceByKey are all spark RDD functions counts = text_file.flatMap(lambda line: line.</description>
    </item>
    
  </channel>
</rss>
