<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tensorflow Tutorial on </title>
    <link>https://www.wikiod.com/docs/tensorflow/</link>
    <description>Recent content in tensorflow Tutorial on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/docs/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Getting started with tensorflow</title>
      <link>https://www.wikiod.com/tensorflow/getting-started-with-tensorflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tensorflow/getting-started-with-tensorflow/</guid>
      <description>Basic Example # Tensorflow is more than just a deep learning framework. It is a general computation framework to perform general mathematical operations in a parallel and distributed manner. An example of such is described below.
Linear Regression # A basic statistical example that is commonly utilized and is rather simple to compute is fitting a line to a dataset. The method to do so in tensorflow is described below in code and comments.</description>
    </item>
    
    <item>
      <title>Using 1D convolution</title>
      <link>https://www.wikiod.com/tensorflow/using-1d-convolution/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tensorflow/using-1d-convolution/</guid>
      <description>Basic example # Update: TensorFlow now supports 1D convolution since version r0.11, using tf.nn.conv1d.
Consider a basic example with an input of length 10, and dimension 16. The batch size is 32. We therefore have a placeholder with input shape [batch_size, 10, 16].
batch_size = 32 x = tf.placeholder(tf.float32, [batch_size, 10, 16]) We then create a filter with width 3, and we take 16 channels as input, and output also 16 channels.</description>
    </item>
    
    <item>
      <title>How to use TensorFlow Graph Collections?</title>
      <link>https://www.wikiod.com/tensorflow/how-to-use-tensorflow-graph-collections/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tensorflow/how-to-use-tensorflow-graph-collections/</guid>
      <description>When you have huge model, it is useful to form some groups of tensors in your computational graph, that are connected with each other. For example tf.GraphKeys class contains such standart collections as:
tf.GraphKeys.VARIABLES tf.GraphKeys.TRAINABLE_VARIABLES tf.GraphKeys.SUMMARIES Create your own collection and use it to collect all your losses. # Here we will create collection for losses of Neural Network&amp;rsquo;s computational graph.
First create a computational graph like so:
with tf.variable_scope(&amp;quot;Layer&amp;quot;): W = tf.</description>
    </item>
    
    <item>
      <title>Save and Restore a Model in TensorFlow</title>
      <link>https://www.wikiod.com/tensorflow/save-and-restore-a-model-in-tensorflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tensorflow/save-and-restore-a-model-in-tensorflow/</guid>
      <description>Tensorflow distinguishes between saving/restoring the current values of all the variables in a graph and saving/restoring the actual graph structure. To restore the graph, you are free to use either Tensorflow&amp;rsquo;s functions or just call your piece of code again, that built the graph in the first place. When defining the graph, you should also think about which and how variables/ops should be retrievable once the graph has been saved and restored.</description>
    </item>
    
    <item>
      <title>Creating RNN, LSTM and bidirectional RNNLSTMs with TensorFlow</title>
      <link>https://www.wikiod.com/tensorflow/creating-rnn-lstm-and-bidirectional-rnnlstms-with-tensorflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tensorflow/creating-rnn-lstm-and-bidirectional-rnnlstms-with-tensorflow/</guid>
      <description>Creating a bidirectional LSTM # import tensorflow as tf dims, layers = 32, 2 # Creating the forward and backwards cells lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(dims, forget_bias=1.0) lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(dims, forget_bias=1.0) # Pass lstm_fw_cell / lstm_bw_cell directly to tf.nn.bidrectional_rnn # if only a single layer is needed lstm_fw_multicell = tf.nn.rnn_cell.MultiRNNCell([lstm_fw_cell]*layers) lstm_bw_multicell = tf.nn.rnn_cell.MultiRNNCell([lstm_bw_cell]*layers) # tf.nn.bidirectional_rnn takes a list of tensors with shape # [batch_size x cell_fw.state_size], so separate the input into discrete # timesteps.</description>
    </item>
    
    <item>
      <title>Using Batch Normalization</title>
      <link>https://www.wikiod.com/tensorflow/using-batch-normalization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tensorflow/using-batch-normalization/</guid>
      <description>Parameters # contrib.layers.batch_norm params Remarks beta python bool type. Whether or not to center the moving_mean and moving_variance &amp;mdash;&amp;mdash; &amp;mdash;&amp;mdash; gamma python bool type. Whether or not to scale the moving_mean and moving_variance &amp;mdash;&amp;mdash; &amp;mdash;&amp;mdash; is_training Accepts python bool or TensorFlow tf.palceholder(tf.bool) &amp;mdash;&amp;mdash; &amp;mdash;&amp;mdash; decay The default setting is decay=0.999. A smaller value (i.e. decay=0.9) is better for smaller dataset and/or less training steps. Here is a screen shot of the result of the working example above.</description>
    </item>
    
    <item>
      <title>Using if condition inside the TensorFlow graph with tf.cond</title>
      <link>https://www.wikiod.com/tensorflow/using-if-condition-inside-the-tensorflow-graph-with-tfcond/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tensorflow/using-if-condition-inside-the-tensorflow-graph-with-tfcond/</guid>
      <description>Parameters # Parameter Details pred a TensorFlow tensor of type bool fn1 a callable function, with no argument fn2 a callable function, with no argument name (optional) name for the operation pred cannot be just True or False, it needs to be a Tensor The function fn1 and fn2 should return the same number of outputs, with the same types. Basic example # x = tf.constant(1.) bool = tf.constant(True) res = tf.</description>
    </item>
    
    <item>
      <title>How to debug a memory leak in TensorFlow</title>
      <link>https://www.wikiod.com/tensorflow/how-to-debug-a-memory-leak-in-tensorflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tensorflow/how-to-debug-a-memory-leak-in-tensorflow/</guid>
      <description>Use Graph.finalize() to catch nodes being added to the graph # The most common mode of using TensorFlow involves first building a dataflow graph of TensorFlow operators (like tf.constant() and tf.matmul(), then running steps by calling the tf.Session.run() method in a loop (e.g. a training loop).
A common source of memory leaks is where the training loop contains calls that add nodes to the graph, and these run in every iteration, causing the graph to grow.</description>
    </item>
    
    <item>
      <title>Measure the execution time of individual operations</title>
      <link>https://www.wikiod.com/tensorflow/measure-the-execution-time-of-individual-operations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tensorflow/measure-the-execution-time-of-individual-operations/</guid>
      <description>Basic example with TensorFlow&amp;rsquo;s Timeline object # The Timeline object allows you to get the execution time for each node in the graph:
you use a classic sess.run() but also specify the optional arguments options and run_metadata you then create a Timeline object with the run_metadata.step_stats data Here is an example program that measures the performance of a matrix multiplication:
import tensorflow as tf from tensorflow.python.client import timeline x = tf.</description>
    </item>
    
    <item>
      <title>Reading the data</title>
      <link>https://www.wikiod.com/tensorflow/reading-the-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tensorflow/reading-the-data/</guid>
      <description>How to load images and labels from a TXT file # It has not been explained in the Tensorflow documentation how to load images and labels directly from a TXT file. The code below illustrates how I achieved it. However, it does not mean that is the best way to do it and that this way will help in further steps.
For instance, I&amp;rsquo;m loading the labels in one single integer value {0,1} while the documentation uses a one-hot vector [0,1].</description>
    </item>
    
  </channel>
</rss>
