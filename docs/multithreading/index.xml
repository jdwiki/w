<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>multithreading Tutorial on </title>
    <link>https://www.wikiod.com/docs/multithreading/</link>
    <description>Recent content in multithreading Tutorial on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/docs/multithreading/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Getting started with multithreading</title>
      <link>https://www.wikiod.com/multithreading/getting-started-with-multithreading/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/multithreading/getting-started-with-multithreading/</guid>
      <description>Deadlocks # A deadlock occurs when every member of some group of two or more threads must wait for one of the other members to do something (e.g., to release a lock) before it can proceed. Without intervention, the threads will wait forever.
A pseudocode example of a deadlock-prone design is:
thread_1 { acquire(A) ... acquire(B) ... release(A, B) } thread_2 { acquire(B) ... acquire(A) ... release(A, B) } A deadlock can occur when thread_1 has acquired A, but not yet B, and thread_2 has acquired B, but not A.</description>
    </item>
    
    <item>
      <title>Executors</title>
      <link>https://www.wikiod.com/multithreading/executors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/multithreading/executors/</guid>
      <description>Syntax # ThreadPoolExecutor
ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue)
ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue, RejectedExecutionHandler handler)
ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue, ThreadFactory threadFactory)
ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)
Executors.callable(PrivilegedAction&amp;lt;?&amp;gt; action)
Executors.callable(PrivilegedExceptionAction&amp;lt;?&amp;gt; action)
Executors.callable(Runnable task)
Executors.callable(Runnable task, T result)
Executors.defaultThreadFactory()
Executors.newCachedThreadPool()
Executors.newCachedThreadPool(ThreadFactory threadFactory)
Executors.newFixedThreadPool(int nThreads)
Executors.newFixedThreadPool(int nThreads, ThreadFactory threadFactory)</description>
    </item>
    
    <item>
      <title>Semaphores &amp; Mutexes</title>
      <link>https://www.wikiod.com/multithreading/semaphores--mutexes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/multithreading/semaphores--mutexes/</guid>
      <description>Semaphores &amp;amp; Mutexes are concurrency controls used to synchronize multiple thread access to shared resources.
Semaphore # Here&amp;rsquo;s a brilliant explanation from this Stackoverflow question:
Think of semaphores as bouncers at a nightclub. There are a dedicated number of people that are allowed in the club at once. If the club is full no one is allowed to enter, but as soon as one person leaves another person might enter.</description>
    </item>
    
  </channel>
</rss>
