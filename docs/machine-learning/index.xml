<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine-learning Tutorial on </title>
    <link>https://www.wikiod.com/docs/machine-learning/</link>
    <description>Recent content in machine-learning Tutorial on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/docs/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Getting started with machine-learning</title>
      <link>https://www.wikiod.com/machine-learning/getting-started-with-machine-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/machine-learning/getting-started-with-machine-learning/</guid>
      <description>Installation or Setup using Python # 1) scikit learn
scikit-learn is a Python module for machine learning built on top of SciPy and distributed under the 3-Clause BSD license. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.
The current stable version of scikit-learn requires:</description>
    </item>
    
    <item>
      <title>Perceptron</title>
      <link>https://www.wikiod.com/machine-learning/perceptron/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/machine-learning/perceptron/</guid>
      <description>Implementing a Perceptron model in C++ # In this example I will go through the implementation of the perceptron model in C++ so that you can get a better idea of how it works.
First things first it is a good practice to write down a simple algorithm of what we want to do.
Algorithm:
Make a the vector for the weights and initialize it to 0 (Don&amp;rsquo;t forget to add the bias term) Keep adjusting the weights until we get 0 errors or a low error count.</description>
    </item>
    
    <item>
      <title>Supervised Learning</title>
      <link>https://www.wikiod.com/machine-learning/supervised-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/machine-learning/supervised-learning/</guid>
      <description>Linear Regression # Since Supervised Learning consists of a target or outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables). Using these set of variables, we generate a function that map inputs to desired outputs. The training process continues until the model achieves a desired level of accuracy on the training data.
Therefore,there are many examples of Supervised Learning algorithms,so in this case I would like to focus on Linear Regression</description>
    </item>
    
    <item>
      <title>Neural Networks</title>
      <link>https://www.wikiod.com/machine-learning/neural-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/machine-learning/neural-networks/</guid>
      <description>Activation Functions # Activation functions also known as transfer function is used to map input nodes to output nodes in certain fashion.
They are used to impart non linearity to the output of a neural network layer.
Some commonly used functions and their curves are given below: Sigmoid Function # The sigmoid is a squashing function whose output is in the range [0, 1].
The code for implementing sigmoid along with its derivative with numpy is shown below:</description>
    </item>
    
    <item>
      <title>Evaluation Metrics</title>
      <link>https://www.wikiod.com/machine-learning/evaluation-metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/machine-learning/evaluation-metrics/</guid>
      <description>Area Under the Curve of the Receiver Operating Characteristic (AUROC) # The AUROC is one of the most commonly used metric to evaluate a classifier&amp;rsquo;s performances. This section explains how to compute it.
AUC (Area Under the Curve) is used most of the time to mean AUROC, which is a bad practice as AUC is ambiguous (could be any curve) while AUROC is not.
Overview â€“ Abbreviations # Abbreviation Meaning AUROC Area Under the Curve of the Receiver Operating Characteristic AUC Area Under the Curce ROC Receiver Operating Characteristic TP True Positives TN True Negatives FP False Positives FN False Negatives TPR True Positive Rate FPR False Positive Rate Interpreting the AUROC # The AUROC has several equivalent interpretations:</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>https://www.wikiod.com/machine-learning/deep-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/machine-learning/deep-learning/</guid>
      <description>Deep Learning is a sub-field of machine learning where multi-layer artificial neural networks are used for learning purpose. Deep Learning has found lots of great implementations, e.g. Speech Recognition, Subtitles on Youtube, Amazon recommendation, and so on. For additional information there is a dedicated topic to deep-learning.
Short brief of Deep learning # To train a neural network, firstly we need to design a good and efficient idea. There are three types of learning tasks.</description>
    </item>
    
    <item>
      <title>Machine Learning Using Java</title>
      <link>https://www.wikiod.com/machine-learning/machine-learning-using-java/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/machine-learning/machine-learning-using-java/</guid>
      <description>tools list # Cortical.io - Retina: an API performing complex NLP operations (disambiguation, classification, streaming text filtering, etc...) as quickly and intuitively as the brain. CoreNLP - Stanford CoreNLP provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words Stanford Parser - A natural language parser is a program that works out the grammatical structure of sentences Stanford POS Tagger - A Part-Of-Speech Tagger (POS Tagger Stanford Name Entity Recognizer - Stanford NER is a Java implementation of a Named Entity Recognizer.</description>
    </item>
    
    <item>
      <title>Scikit Learn</title>
      <link>https://www.wikiod.com/machine-learning/scikit-learn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/machine-learning/scikit-learn/</guid>
      <description>A Basic Simple Classification Problem(XOR) using k nearest neighbor algorithm # Consider you want to predict the correct answer for XOR popular problem. You Knew what is XOR(e.g [x0 x1] =&amp;gt; y). for example [0 0] =&amp;gt; 0, [0 1] =&amp;gt; 1 and&amp;hellip;
#Load Sickit learn data from sklearn.neighbors import KNeighborsClassifier #X is feature vectors, and y is correct label(To train model) X = [[0, 0],[0 ,1],[1, 0],[1, 1]] y = [0,1,1,0] #Initialize a Kneighbors Classifier with K parameter set to 2 KNC = KNeighborsClassifier(n_neighbors= 2) #Fit the model(the KNC learn y Given X) KNC.</description>
    </item>
    
    <item>
      <title>SVM</title>
      <link>https://www.wikiod.com/machine-learning/svm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/machine-learning/svm/</guid>
      <description>Difference between logistic regression and SVM # Decision boundary when we classify using logistic regression- Decision boundary when we classify using SVM-
As it can be observed, SVM tries to maintain a &amp;lsquo;gap&amp;rsquo; on either side of the decision boundary. This proves helpful when we encounter new data.
With new data-
Logistic regression performs poorly (new red circle is classified as blue) -
Whereas SVM can classify it correctly (the new red circle is classified correctly in red side)-</description>
    </item>
    
    <item>
      <title>Machine learning and it&#39;s classification</title>
      <link>https://www.wikiod.com/machine-learning/machine-learning-and-its-classification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/machine-learning/machine-learning-and-its-classification/</guid>
      <description>What is machine learning ? # Two definitions of Machine Learning are offered. Arthur Samuel described it as:
the field of study that gives computers the ability to learn without being explicitly programmed.
This is an older, informal definition.
Tom Mitchell provides a more modern definition:
A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.</description>
    </item>
    
  </channel>
</rss>
