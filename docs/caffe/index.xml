<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>caffe Tutorial on </title>
    <link>https://www.wikiod.com/docs/caffe/</link>
    <description>Recent content in caffe Tutorial on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/docs/caffe/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Getting started with caffe</title>
      <link>https://www.wikiod.com/caffe/getting-started-with-caffe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/caffe/getting-started-with-caffe/</guid>
      <description>Installation and setup # Ubuntu # Below are detailed instructions to install Caffe, pycaffe as well as its dependencies, on Ubuntu 14.04 x64 or 14.10 x64.
Execute the following script, e.g. &amp;ldquo;bash compile_caffe_ubuntu_14.sh&amp;rdquo; (~30 to 60 minutes on a new Ubuntu).
# This script installs Caffe and pycaffe. # CPU only, multi-threaded Caffe. # Usage: # 0. Set up here how many cores you want to use during the installation: # By default Caffe will use all these cores.</description>
    </item>
    
    <item>
      <title>Batch normalization</title>
      <link>https://www.wikiod.com/caffe/batch-normalization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/caffe/batch-normalization/</guid>
      <description>From the docs:
&amp;ldquo;Normalizes the input to have 0-mean and/or unit (1) variance across the batch.
This layer computes Batch Normalization as described in 1.
[&amp;hellip;]
1 S. Ioffe and C. Szegedy, &amp;ldquo;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.&amp;rdquo; arXiv preprint arXiv:1502.03167 (2015).&amp;rdquo;
Parameters # Parameter Details use_global_stats From rohrbach&amp;rsquo;s post from 2nd March 2016 - maybe he knows: (use_global_stats) &amp;ldquo;By default, during training time, the network is computing global mean/ variance statistics via a running average, which is then used at test time to allow deterministic outputs for each input.</description>
    </item>
    
    <item>
      <title>Prepare Data for Training</title>
      <link>https://www.wikiod.com/caffe/prepare-data-for-training/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/caffe/prepare-data-for-training/</guid>
      <description>Prepare image dataset for image classification task # Caffe has a build-in input layer tailored for image classification tasks (i.e., single integer label per input image). This input &amp;quot;Data&amp;quot; layer is built upon an [tag:lmdb] or [tag:leveldb] data structure. In order to use &amp;quot;Data&amp;quot; layer one has to construct the data structure with all training data.
A quick guide to Caffe&#39;s `convert_imageset` Build First thing you must do is build caffe and caffe&#39;s tools (`convert_imageset` is one of these tools).</description>
    </item>
    
    <item>
      <title>Training a Caffe model with pycaffe</title>
      <link>https://www.wikiod.com/caffe/training-a-caffe-model-with-pycaffe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/caffe/training-a-caffe-model-with-pycaffe/</guid>
      <description>Training a network on the Iris dataset # Given below is a simple example to train a Caffe model on the Iris data set in Python, using PyCaffe. It also gives the predicted outputs given some user-defined inputs.
iris_tuto.py
import subprocess import platform import copy from sklearn.datasets import load_iris import sklearn.metrics import numpy as np from sklearn.cross_validation import StratifiedShuffleSplit import matplotlib.pyplot as plt import h5py import caffe import caffe.draw def load_data(): &#39;&#39;&#39; Load Iris Data set &#39;&#39;&#39; data = load_iris() print(data.</description>
    </item>
    
    <item>
      <title>Basic Caffe Objects - Solver, Net, Layer and Blob</title>
      <link>https://www.wikiod.com/caffe/basic-caffe-objects---solver-net-layer-and-blob/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/caffe/basic-caffe-objects---solver-net-layer-and-blob/</guid>
      <description>A caffe user sends instructions to perform specific operations to caffe objects. These objects interact with each other based on their design specifications and carry out the operation(s). This is a basic principle OOP paradigm.
While there are many caffe object types (or C++ classes), for a beginning basic understanding we focus upon 4 important caffe objects. Our objective at this stage is to simply observe the interaction between these objects on a highly abstracted level where specific implementation and design details are hazed out, and instead a bird&amp;rsquo;s eye view of operation is focussed upon.</description>
    </item>
    
    <item>
      <title>Custom Python Layers</title>
      <link>https://www.wikiod.com/caffe/custom-python-layers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/caffe/custom-python-layers/</guid>
      <description>This tutorial will guide through the steps to create a simple custom layer for Caffe using python. By the end of it, there are some examples of custom layers. Usually you would create a custom layer to implement a functionality that isn&amp;rsquo;t available in Caffe, tuning it for your requirements.
Creating a python custom layer adds some overhead to your network and probably isn&amp;rsquo;t as efficient as a C++ custom layer.</description>
    </item>
    
  </channel>
</rss>
