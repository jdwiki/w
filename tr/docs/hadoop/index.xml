<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hadoop Eğitimi on </title>
    <link>https://www.wikiod.com/tr/docs/hadoop/</link>
    <description>Recent content in hadoop Eğitimi on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/tr/docs/hadoop/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>hadoop&#39;u kullanmaya başlama</title>
      <link>https://www.wikiod.com/tr/hadoop/hadoopu-kullanmaya-baslama/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/hadoop/hadoopu-kullanmaya-baslama/</guid>
      <description>ubuntu üzerinde Hadoop kurulumu # Hadoop Kullanıcısı Oluşturma: # sudo addgroup hadoop Kullanıcı ekleme: # sudo adduser --ingroup hadoop hduser001 SSH&amp;rsquo;yi Yapılandırma: # su -hduser001 ssh-keygen -t rsa -P &amp;quot;&amp;quot; cat .ssh/id rsa.pub &amp;gt;&amp;gt; .ssh/authorized_keys Not: Yetkili anahtarı yazarken [bash: .ssh/authorized_keys: Böyle bir dosya veya dizin yok] hatası alırsanız. burayı kontrol edin.
sudoer&amp;rsquo;ın listesine hadoop kullanıcısını ekleyin: # sudo adduser hduser001 sudo IPv6&amp;rsquo;yı devre dışı bırakma: # Hadoop&amp;rsquo;u Yüklemek: # sudo add-apt-repository ppa:hadoop-ubuntu/stable sudo apt-get install hadoop Linux&amp;rsquo;ta Kurulum veya Kurulum # Sözde Dağıtılmış Küme Kurulum Prosedürü</description>
    </item>
    
    <item>
      <title>Hadoop komutları</title>
      <link>https://www.wikiod.com/tr/hadoop/hadoop-komutlar/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/hadoop/hadoop-komutlar/</guid>
      <description>Sözdizimi # Hadoop v1 komutları: hadoop fs -&amp;lt;komut&amp;gt;
Hadoop v2 komutları: hdfs dfs -&amp;lt;komut&amp;gt;
Hadoop v1 Komutları # 1. Hadoop sürümünü yazdırın # hadoop version 2. HDFS&amp;rsquo;deki kök dizinin içeriğini listeleyin # # hadoop fs -ls / 3. Kullanılan alan miktarını bildirin ve # şu anda takılı dosya sisteminde mevcut # # hadoop fs -df hdfs:/ 4. Altındaki dizinlerin, dosyaların ve baytların sayısını sayın. # belirtilen dosya kalıbıyla eşleşen yollar # # hadoop fs -count hdfs:/ 5.</description>
    </item>
    
    <item>
      <title>HDFS nedir?</title>
      <link>https://www.wikiod.com/tr/hadoop/hdfs-nedir/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/hadoop/hdfs-nedir/</guid>
      <description>HDFS&amp;rsquo;nin ve nasıl çalıştığının iyi bir açıklaması.
Sözdizimi, HDFS&amp;rsquo;de kullanılabilecek komutları içermelidir.
HDFS&amp;rsquo;de dosya bulma # Hadoop Dağıtılmış dosya sisteminde bir dosya bulmak için:
hdfs dfs -ls -R / | grep [search_term] Yukarıdaki komutta,
-ls dosyaları listelemek içindir
&amp;lsquo;-R&amp;rsquo; özyinelemeli (alt dizinler arasında yineleme) içindir
/ kök dizinden anlamına gelir
| ilk komutun çıktısını ikinciye aktarmak için
eşleşen dizeleri çıkarmak için grep komutu
hadoop dosya sistemindeki tüm dosyalar listesinde aranacak [search_term] dosya adı.</description>
    </item>
    
    <item>
      <title>MapReduce&#39;a Giriş</title>
      <link>https://www.wikiod.com/tr/hadoop/mapreducea-giris/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/hadoop/mapreducea-giris/</guid>
      <description>Sözdizimi # Örneği çalıştırmak için komut sözdizimi şöyledir:
bin/hadoop jar hadoop-*-examples.jar wordcount [-m &amp;lt;#maps&amp;gt;] [-r &amp;lt;#reducers&amp;gt;] &amp;lt;in-dir&amp;gt; &amp;lt;out-dir&amp;gt; Verileri HDFS&amp;rsquo;ye kopyalamak için (yerelden):
bin/hadoop dfs -mkdir &amp;lt;hdfs-dir&amp;gt; //not required in hadoop 0.17.2 and later bin/hadoop dfs -copyFromLocal &amp;lt;local-dir&amp;gt; &amp;lt;hdfs-dir&amp;gt; Hadoop&amp;rsquo;ta MapReduce kullanan Word Count programı.
Kelime Sayım Programı(Java ve Python&amp;rsquo;da) # Kelime sayma programı MapReduce&amp;rsquo;daki &amp;ldquo;Merhaba Dünya&amp;rdquo; programı gibidir.
Hadoop MapReduce, büyük miktarda veriyi (çok terabaytlık veri kümeleri) paralel olarak büyük ticari donanım kümelerinde (binlerce düğüm) güvenilir, hataya dayanıklı bir şekilde işleyen uygulamaları kolayca yazmak için bir yazılım çerçevesidir.</description>
    </item>
    
    <item>
      <title>Hadoop yük verileri</title>
      <link>https://www.wikiod.com/tr/hadoop/hadoop-yuk-verileri/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/hadoop/hadoop-yuk-verileri/</guid>
      <description>Verileri hadoop hdfs&amp;rsquo;e yükleyin # ADIM 1: HDFS&amp;rsquo;DE BİR DİZİN OLUŞTURUN, BİR DOSYA YÜKLEYİN VE İÇERİKLERİ LİSTEYİN
Sözdizimini yazarak öğrenelim. Aşağıdaki örnek komutları kopyalayıp terminalinize yapıştırabileceksiniz:
hadoop fs -mkdir: # Argüman olarak yol URI&amp;rsquo;lerini alır ve bir dizin veya birden çok dizin oluşturur.
Kullanım: # # hadoop fs -mkdir &amp;lt;paths&amp;gt; Örnek: # hadoop fs -mkdir /user/hadoop hadoop fs -mkdir /user/hadoop/dir1 /user/hadoop/dir2 /user/hadoop/dir3 hadoop fs -put: # Tek src dosyasını veya birden çok src dosyasını yerel dosya sisteminden Hadoop Dağıtılmış Dosya Sistemine kopyalar.</description>
    </item>
    
    <item>
      <title>renk tonu</title>
      <link>https://www.wikiod.com/tr/hadoop/renk-tonu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/hadoop/renk-tonu/</guid>
      <description>Hue, HDFS, Hive, Spark, Hbase, Sqoop, Impala, Pig, Oozie vb. gibi yaygın olarak kullanılan Bigdata teknolojilerinin çoğuna bağlanmak ve bunlarla çalışmak için kullanılan bir Kullanıcı Arabirimidir. Hue, İlişkisel veritabanlarına karşı sorgu çalıştırmayı da destekler.
Bir Django web uygulaması olan Hue, öncelikle Hive sorgularını çalıştırmak için bir çalışma tezgahı olarak oluşturulmuştur. Daha sonra, Hue&amp;rsquo;nun işlevselliği, Hadoop Ekosisteminin farklı bileşenlerini desteklemek için artırıldı. Apache Lisansı altında açık kaynaklı yazılım olarak mevcuttur.
Ubuntu&amp;rsquo;da Hue Kurulumu # Bu kurulum, &amp;ldquo;hadoop&amp;quot;un &amp;ldquo;hadoop&amp;rdquo; kullanıcısı altında önceden yüklenmiş olduğunu varsayar.</description>
    </item>
    
    <item>
      <title>Yerel Eclipse dev ortamında Hadoop MR Java kodunda hata ayıklama.</title>
      <link>https://www.wikiod.com/tr/hadoop/yerel-eclipse-dev-ortamnda-hadoop-mr-java-kodunda-hata-ayklama/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/hadoop/yerel-eclipse-dev-ortamnda-hadoop-mr-java-kodunda-hata-ayklama/</guid>
      <description>Burada hatırlanması gereken temel şey, bir Hadoop MR işinde hata ayıklamanın Eclipse&amp;rsquo;deki herhangi bir uzaktan hata ayıklanmış uygulamaya benzer olacağıdır.
Hata ayıklayıcı veya hata ayıklama aracı, diğer programları (&amp;ldquo;hedef&amp;rdquo; program) test etmek ve hatalarını ayıklamak için kullanılan bir bilgisayar programıdır. Hataya çok az yer olan ve küçük bir hatanın büyük kayıplara neden olabileceği bir Hadoop ortamı için özellikle yararlıdır.
Tek yapman gereken bu.
Yapılandırma adımları # Bildiğiniz gibi, Hadoop yerel ortamda 3 farklı modda çalıştırılabilir:</description>
    </item>
    
  </channel>
</rss>
