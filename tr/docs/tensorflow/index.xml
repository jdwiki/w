<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tensorflow Eğitimi on </title>
    <link>https://www.wikiod.com/tr/docs/tensorflow/</link>
    <description>Recent content in tensorflow Eğitimi on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/tr/docs/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>tensorflow&#39;a başlarken</title>
      <link>https://www.wikiod.com/tr/tensorflow/tensorflowa-baslarken/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/tensorflow/tensorflowa-baslarken/</guid>
      <description>Temel Örnek # Tensorflow, yalnızca bir derin öğrenme çerçevesinden daha fazlasıdır. Genel matematiksel işlemleri paralel ve dağıtılmış bir şekilde gerçekleştirmek için genel bir hesaplama çerçevesidir. Bunun bir örneği aşağıda açıklanmıştır.
Doğrusal Regresyon # Yaygın olarak kullanılan ve hesaplanması oldukça basit olan temel bir istatistiksel örnek, bir veri kümesine bir satır sığdırmaktır. Tensorflow&amp;rsquo;ta bunu yapmanın yöntemi, aşağıda kod ve yorumlarda açıklanmıştır.
(TensorFlow) komut dosyasının ana adımları şunlardır:
yer tutucular (x_ph, y_ph) ve değişkenler (W, b) bildirin Başlatma operatörünü (&amp;lsquo;init&amp;rsquo;) tanımlayın Yer tutucular ve değişkenler üzerindeki işlemleri bildirin (y_pred, loss, train_op) Bir oturum oluşturun (sess) Başlatma operatörünü çalıştırın (sess.</description>
    </item>
    
    <item>
      <title>1B evrişim kullanma</title>
      <link>https://www.wikiod.com/tr/tensorflow/1b-evrisim-kullanma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/tensorflow/1b-evrisim-kullanma/</guid>
      <description>Temel örnek # Güncelleme: TensorFlow artık [tf.nn.conv1d](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn. html#conv1d).
&amp;ldquo;10&amp;rdquo; uzunluğunda ve &amp;ldquo;16&amp;rdquo; boyutunda bir girdiye sahip temel bir örnek düşünün. Parti boyutu &amp;ldquo;32&amp;quot;dir. Bu nedenle, &amp;ldquo;[batch_size, 10, 16]&amp;rdquo; giriş şekline sahip bir yer tutucumuz var.
batch_size = 32 x = tf.placeholder(tf.float32, [batch_size, 10, 16]) Daha sonra genişliği 3 olan bir filtre oluşturuyoruz ve &amp;lsquo;16&amp;rsquo; kanalları girdi olarak alıyoruz ve çıktı olarak da &amp;lsquo;16&amp;rsquo; kanalları alıyoruz.
filter = tf.zeros([3, 16, 16]) # these should be real values, not 0 Son olarak, bir adım ve bir dolgu ile &amp;rsquo;tf.</description>
    </item>
    
    <item>
      <title>TensorFlow Grafik Koleksiyonları nasıl kullanılır?</title>
      <link>https://www.wikiod.com/tr/tensorflow/tensorflow-grafik-koleksiyonlar-nasl-kullanlr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/tensorflow/tensorflow-grafik-koleksiyonlar-nasl-kullanlr/</guid>
      <description>Çok büyük bir modeliniz olduğunda, hesaplama grafiğinizde birbiriyle bağlantılı bazı tensör grupları oluşturmak yararlıdır. Örneğin tf.GraphKeys sınıfı aşağıdaki gibi standart koleksiyonları içerir:
tf.GraphKeys.VARIABLES tf.GraphKeys.TRAINABLE_VARIABLES tf.GraphKeys.SUMMARIES Kendi koleksiyonunuzu oluşturun ve tüm kayıplarınızı toplamak için kullanın. # Burada Neural Network&amp;rsquo;ün hesaplama grafiğinin kayıpları için bir koleksiyon oluşturacağız.
İlk önce şöyle bir hesaplama grafiği oluşturun:
with tf.variable_scope(&amp;quot;Layer&amp;quot;): W = tf.get_variable(&amp;quot;weights&amp;quot;, [m, k], initializer=tf.zeros_initializer([m, k], dtype=tf.float32)) b1 = tf.get_variable(&amp;quot;bias&amp;quot;, [k], initializer = tf.zeros_initializer([k], dtype=tf.float32)) z = tf.</description>
    </item>
    
    <item>
      <title>TensorFlow&#39;da Bir Modeli Kaydetme ve Geri Yükleme</title>
      <link>https://www.wikiod.com/tr/tensorflow/tensorflowda-bir-modeli-kaydetme-ve-geri-yukleme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/tensorflow/tensorflowda-bir-modeli-kaydetme-ve-geri-yukleme/</guid>
      <description>Tensorflow, bir grafikteki tüm değişkenlerin mevcut değerlerini kaydetme/geri yükleme ile gerçek grafik yapısını kaydetme/geri yükleme arasında ayrım yapar. Grafiği geri yüklemek için, Tensorflow&amp;rsquo;un işlevlerini kullanmakta özgürsünüz ya da ilk etapta grafiği oluşturan kod parçanızı tekrar çağırabilirsiniz. Grafiği tanımlarken, grafik kaydedildikten ve geri yüklendikten sonra hangi değişkenlerin/işlemlerin geri alınabileceğini de düşünmelisiniz.
Yukarıdaki model geri yükleme bölümünde, eğer doğru anladıysam, modeli oluşturuyorsunuz ve ardından değişkenleri geri yüklüyorsunuz. tf.add_to_collection() kullanarak kaydederken ilgili tensörleri/yer tutucuları eklediğiniz sürece modeli yeniden oluşturmanın gerekli olmadığına inanıyorum.</description>
    </item>
    
    <item>
      <title>TensorFlow ile RNN, LSTM ve çift yönlü RNNLSTM&#39;ler oluşturma</title>
      <link>https://www.wikiod.com/tr/tensorflow/tensorflow-ile-rnn-lstm-ve-cift-yonlu-rnnlstmler-olusturma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/tensorflow/tensorflow-ile-rnn-lstm-ve-cift-yonlu-rnnlstmler-olusturma/</guid>
      <description>Çift yönlü bir LSTM oluşturma # import tensorflow as tf dims, layers = 32, 2 # Creating the forward and backwards cells lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(dims, forget_bias=1.0) lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(dims, forget_bias=1.0) # Pass lstm_fw_cell / lstm_bw_cell directly to tf.nn.bidrectional_rnn # if only a single layer is needed lstm_fw_multicell = tf.nn.rnn_cell.MultiRNNCell([lstm_fw_cell]*layers) lstm_bw_multicell = tf.nn.rnn_cell.MultiRNNCell([lstm_bw_cell]*layers) # tf.nn.bidirectional_rnn takes a list of tensors with shape # [batch_size x cell_fw.state_size], so separate the input into discrete # timesteps.</description>
    </item>
    
    <item>
      <title>Toplu Normalleştirmeyi Kullanma</title>
      <link>https://www.wikiod.com/tr/tensorflow/toplu-normallestirmeyi-kullanma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/tensorflow/toplu-normallestirmeyi-kullanma/</guid>
      <description>Parametreler # katkı.layers.batch_norm parametreleri Açıklamalar &amp;ldquo;beta&amp;rdquo; piton &amp;ldquo;bool&amp;rdquo; türü. &amp;lsquo;moving_mean&amp;rsquo; ve &amp;lsquo;moving_variance&amp;rsquo; &amp;mdash;&amp;mdash; &amp;mdash;&amp;mdash; &amp;ldquo;gama&amp;rdquo; piton &amp;ldquo;bool&amp;rdquo; türü. &amp;lsquo;moving_mean&amp;rsquo; ve &amp;lsquo;moving_variance&amp;rsquo;ın ölçeklenip ölçeklenmeyeceği &amp;mdash;&amp;mdash; &amp;mdash;&amp;mdash; is_eğitim Python &amp;lsquo;bool&amp;rsquo; veya TensorFlow &amp;rsquo;tf.palceholder(tf.bool)&amp;rsquo; &amp;mdash;&amp;mdash; &amp;mdash;&amp;mdash; &amp;lsquo;çürüme&amp;rsquo; Varsayılan ayar &amp;lsquo;decay=0.999&amp;rsquo; şeklindedir. Daha küçük bir değer (yani decay=0.9), daha küçük veri kümesi ve/veya daha az eğitim adımı için daha iyidir. İşte yukarıdaki çalışma örneğinin sonucunun bir ekran görüntüsü.
Bu çalışma örneğinin kodu ve jupyter notebook versiyonu yazarın deposunda bulunabilir.</description>
    </item>
    
    <item>
      <title>tf.cond ile TensorFlow grafiğinin içindeki if koşulunu kullanma</title>
      <link>https://www.wikiod.com/tr/tensorflow/tfcond-ile-tensorflow-grafiginin-icindeki-if-kosulunu-kullanma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/tensorflow/tfcond-ile-tensorflow-grafiginin-icindeki-if-kosulunu-kullanma/</guid>
      <description>Parametreler # parametre Detaylar ön &amp;ldquo;bool&amp;rdquo; türünde bir TensorFlow tensörü fn1 çağrılabilir bir işlev, argümansız fn2 çağrılabilir bir işlev, argümansız isim (isteğe bağlı) işlemin adı &amp;ldquo;pred&amp;rdquo; sadece &amp;ldquo;True&amp;rdquo; veya &amp;ldquo;False&amp;rdquo; olamaz, bir Tensör olması gerekir &amp;ldquo;fn1&amp;rdquo; ve &amp;ldquo;fn2&amp;rdquo; işlevi, aynı türlerle aynı sayıda çıktı döndürmelidir. Temel örnek # x = tf.constant(1.) bool = tf.constant(True) res = tf.cond(bool, lambda: tf.add(x, 1.), lambda: tf.add(x, 10.)) # sess.run(res) will give you 2. f1 ve f2 birden fazla tensör döndürdüğünde # &amp;lsquo;fn1&amp;rsquo; ve &amp;lsquo;fn2&amp;rsquo; iki işlevi birden fazla tensör döndürebilir, ancak tam olarak aynı sayıda ve türde çıktı döndürmeleri gerekir.</description>
    </item>
    
    <item>
      <title>TensorFlow&#39;da bellek sızıntısında nasıl hata ayıklanır</title>
      <link>https://www.wikiod.com/tr/tensorflow/tensorflowda-bellek-szntsnda-nasl-hata-ayklanr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/tensorflow/tensorflowda-bellek-szntsnda-nasl-hata-ayklanr/</guid>
      <description>Grafiğe eklenen düğümleri yakalamak için Graph.finalize() kullanın # TensorFlow kullanmanın en yaygın modu, önce TensorFlow operatörlerinin (tf.constant() ve tf.matmul() gibi) bir veri akışı grafiği oluşturmayı, ardından bir döngüde tf.Session.run() yöntemi (ör. bir eğitim döngüsü).
Yaygın bir bellek sızıntısı kaynağı, eğitim döngüsünün grafiğe düğümler ekleyen çağrıları içerdiği ve bunların her yinelemede çalıştırılarak grafiğin büyümesine neden olduğu yerdir. Bunlar açık (ör. &amp;ldquo;tf.square()&amp;rdquo; gibi bir TensorFlow operatörüne yapılan bir çağrı), örtük (ör. örneğin, bir &amp;ldquo;tf.</description>
    </item>
    
    <item>
      <title>Bireysel işlemlerin yürütme süresini ölçün</title>
      <link>https://www.wikiod.com/tr/tensorflow/bireysel-islemlerin-yurutme-suresini-olcun/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/tensorflow/bireysel-islemlerin-yurutme-suresini-olcun/</guid>
      <description>TensorFlow&amp;rsquo;un Timeline nesnesiyle temel örnek # [Zaman Çizelgesi nesnesi2, grafikteki her bir düğüm için yürütme süresini almanıza olanak tanır:
klasik bir &amp;ldquo;sess.run()&amp;rdquo; kullanıyorsunuz, ancak &amp;ldquo;options&amp;rdquo; ve &amp;ldquo;run_metadata&amp;rdquo; isteğe bağlı bağımsız değişkenlerini de belirtiyorsunuz daha sonra &amp;ldquo;run_metadata.step_stats&amp;rdquo; verileriyle bir &amp;ldquo;Zaman Çizelgesi&amp;rdquo; nesnesi yaratırsınız Matris çarpımının performansını ölçen örnek bir program aşağıda verilmiştir:
import tensorflow as tf from tensorflow.python.client import timeline x = tf.random_normal([1000, 1000]) y = tf.random_normal([1000, 1000]) res = tf.matmul(x, y) # Run the graph with full trace option with tf.</description>
    </item>
    
    <item>
      <title>verileri okumak</title>
      <link>https://www.wikiod.com/tr/tensorflow/verileri-okumak/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/tensorflow/verileri-okumak/</guid>
      <description>Bir TXT dosyasından resimler ve etiketler nasıl yüklenir # Tensorflow belgelerinde görüntülerin ve etiketlerin doğrudan bir TXT dosyasından nasıl yükleneceği açıklanmamıştır. Aşağıdaki kod, bunu nasıl başardığımı göstermektedir. Ancak bu, bunu yapmanın en iyi yolunun bu olduğu ve bu yolun sonraki adımlarda yardımcı olacağı anlamına gelmez.
Örneğin, belgeler bir sıcak vektör [0,1] kullanırken, etiketleri tek bir tamsayı değeri {0,1} olarak yüklüyorum.
# Learning how to import images and labels from a TXT file # # TXT file format # # path/to/imagefile_1 label_1 # path/to/imagefile_2 label_2 # .</description>
    </item>
    
  </channel>
</rss>
