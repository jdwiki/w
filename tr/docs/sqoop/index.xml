<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kepçe Eğitimi on </title>
    <link>https://www.wikiod.com/tr/docs/sqoop/</link>
    <description>Recent content in kepçe Eğitimi on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/tr/docs/sqoop/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>sqoop&#39;u kullanmaya başlama</title>
      <link>https://www.wikiod.com/tr/sqoop/sqoopu-kullanmaya-baslama/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/sqoop/sqoopu-kullanmaya-baslama/</guid>
      <description>Kurulum veya Kurulum # Sqoop, tek bir ikili paket olarak gönderilir, ancak iki ayrı parça istemci ve sunucudan oluşur. You need to install server on single node in your cluster. This node will then serve as an entry point for all connecting Sqoop clients. Server acts as a mapreduce client and therefore Hadoop must be installed and configured on machine hosting Sqoop server. Clients can be installed on any arbitrary number of machines.</description>
    </item>
    
    <item>
      <title>Sqoop İçe Aktarma</title>
      <link>https://www.wikiod.com/tr/sqoop/sqoop-ice-aktarma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/sqoop/sqoop-ice-aktarma/</guid>
      <description>Sözdizimi # &amp;lt;rdbms-jdbc-url&amp;gt; // RDBMS JDBC URL&amp;rsquo;si &amp;lt;username&amp;gt; // RDBMS veritabanının kullanıcı adı &amp;lt;password&amp;gt; // RDBMS veritabanının şifresi &amp;lt;table-name&amp;gt; // RDBMS veritabanı tablosu &amp;lt;hdfs-home-dir&amp;gt; // HDFS ana dizini &amp;lt;condition&amp;gt; // WHERE yan tümcesi ile SQL sorgusu biçiminde ifade edilebilen koşul. &amp;lt;sql sorgusu&amp;gt; // SQL Sorgusu &amp;lt;target-dir&amp;gt; // HDFS Hedef Dizini Sqoop, tabloyu bir RDBMS veri kaynağından HDFS&amp;rsquo;ye veya tam tersi şekilde içe aktaran bir Hadoop Komut Satırı aracıdır. İçe aktarılan verilerle etkileşime girmemizi sağlayan bir Java sınıfı oluşturur.</description>
    </item>
    
    <item>
      <title>Sqoop&#39;u diğer veritabanlarınaveri depolarına bağlama</title>
      <link>https://www.wikiod.com/tr/sqoop/sqoopu-diger-veritabanlarnaveri-depolarna-baglama/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/sqoop/sqoopu-diger-veritabanlarnaveri-depolarna-baglama/</guid>
      <description>Çeşitli veri depolarından/veritabanlarından veri almak için bir sqoop betiğinin nasıl kullanılabileceğini gösterir.
JDBC Sürücüsünü Yükle # MS SQL Server veritabanına erişmek için Sqoop, Microsoft&amp;rsquo;tan indirilebilen ek bir JDBC sürücüsü gerektirir. Aşağıdaki adımlar MSSQL Server JDBC sürücüsünü Sqoop&amp;rsquo;a yükleyecektir:
wget &#39;http://download.microsoft.com/download/0/2/A/02AAE597-3865-456C-AE7F-613F99F850A8/sqljdbc_4.0.2206.100_enu.tar.gz&#39; tar -xvzf sqljdbc_4 cp sqljdbc_4.0/enu/sqljdbc4.jar /usr/hdp/current/sqoop-server/lib/ Bağlantıyı doğrulayın # Sunucuya bağlantının geçerli olduğunu kontrol etmek için:
sqoop list-tables --connect &amp;quot;jdbc:sqlserver://&amp;lt;server_ip&amp;gt;:1433;database=&amp;lt;database_name&amp;gt;&amp;quot; --username &amp;lt;user_name&amp;gt; --password &amp;lt;password&amp;gt; Bunu yapmadan önce SqlServer&amp;rsquo;ın yapılandırmasının 1433 bağlantı noktasına uzaktan erişime izin verip vermediğini kontrol etmeniz önerilir.</description>
    </item>
    
    <item>
      <title>Sqoop İhracat</title>
      <link>https://www.wikiod.com/tr/sqoop/sqoop-ihracat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/sqoop/sqoop-ihracat/</guid>
      <description>Sqoop Dışa Aktarma temel örneği # Dışa aktarma aracı, bir dizi dosyayı HDFS&amp;rsquo;den bir RDBMS&amp;rsquo;ye geri aktarır. Hedef tablo veritabanında zaten mevcut olmalıdır. Girdi dosyaları okunur ve kullanıcı tarafından belirlenen sınırlayıcılara göre bir dizi kayıtta ayrıştırılır.
Örnek :
sqoop export \ --connect=&amp;quot;jdbc:&amp;lt;databaseconnector&amp;gt;&amp;quot; \ --username=&amp;lt;username&amp;gt; \ --password=&amp;lt;password&amp;gt; \ --export-dir=&amp;lt;hdfs export directory&amp;gt; \ --table=&amp;lt;tablename&amp;gt; </description>
    </item>
    
    <item>
      <title>Sqoop kullanarak artımlı içe aktarma yoluyla içe aktarılan veri kümelerini birleştirme</title>
      <link>https://www.wikiod.com/tr/sqoop/sqoop-kullanarak-artml-ice-aktarma-yoluyla-ice-aktarlan-veri-kumelerini-birlestirme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/sqoop/sqoop-kullanarak-artml-ice-aktarma-yoluyla-ice-aktarlan-veri-kumelerini-birlestirme/</guid>
      <description>Sqoop artımlı içe aktarma, CDC adı verilen bir olgu nedeniyle ortaya çıkıyor, yani Veri Yakalamayı Değiştir. Şimdi CDC nedir?
CDC, tüm verilerle uğraşmak yerine bireysel veri değişikliklerini yakalayan bir tasarım modelidir. CDC kullanarak tüm veritabanımızı boşaltmak yerine, yalnızca ana veritabanında yapılan veri değişikliklerini yakalayabiliriz.
Örneğin: Bir veri sorunuyla uğraşıyorsak, örneğin, RDBMS&amp;rsquo;ye günlük 1 lakh veri girişi geliyorsa ve bu verileri günlük olarak Hadoop&amp;rsquo;ta almamız gerekiyorsa, o zaman yeni eklenen verileri içe aktarırken almak isteriz.</description>
    </item>
    
  </channel>
</rss>
