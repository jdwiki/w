<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>scikit-learn Eğitimi on </title>
    <link>https://www.wikiod.com/tr/docs/scikit-learn/</link>
    <description>Recent content in scikit-learn Eğitimi on </description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://www.wikiod.com/tr/docs/scikit-learn/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>scikit-learn&#39;i kullanmaya başlama</title>
      <link>https://www.wikiod.com/tr/scikit-learn/scikit-learni-kullanmaya-baslama/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/scikit-learn/scikit-learni-kullanmaya-baslama/</guid>
      <description>scikit-learn kurulumu # Scikit-learn&amp;rsquo;in mevcut kararlı sürümü gerektirir:
Python (&amp;gt;= 2.6 veya &amp;gt;= 3.3), NumPy (&amp;gt;= 1.6.1), SciPy (&amp;gt;= 0.9). Çoğu kurulum için &amp;lsquo;pip&amp;rsquo; python paket yöneticisi python&amp;rsquo;u ve tüm bağımlılıklarını yükleyebilir:
pip install scikit-learn Ancak linux sistemlerinde olası derleme işlemlerinden kaçınmak için &amp;ldquo;conda&amp;rdquo; paket yöneticisinin kullanılması önerilir.
conda install scikit-learn scikit-learn olup olmadığını kontrol etmek için Shell&amp;rsquo;de yürütün:
python -c &#39;import sklearn; print(sklearn.__version__)&#39; Windows ve Mac OSX Kurulumu:
Canopy ve Anaconda her ikisi de Windows, Mac OSX (Linux için de geçerlidir) için geniş bir bilimsel python kitaplığına ek olarak scikit-learn&amp;lsquo;in yeni bir sürümünü sunar.</description>
    </item>
    
    <item>
      <title>Model seçimi</title>
      <link>https://www.wikiod.com/tr/scikit-learn/model-secimi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/scikit-learn/model-secimi/</guid>
      <description>Çapraz doğrulama # Bir tahmin fonksiyonunun parametrelerini öğrenmek ve aynı veriler üzerinde test etmek metodolojik bir hatadır: Az önce gördüğü örneklerin etiketlerini tekrar eden bir model mükemmel bir puana sahip olur, ancak henüz yararlı bir şey tahmin edemezdi. görünmeyen veriler Bu duruma fazla uydurma denir. Bunu önlemek için, (denetimli) bir makine öğrenimi deneyi gerçekleştirirken mevcut verilerin bir kısmını bir test seti &amp;ldquo;X_test, y_test&amp;rdquo; olarak tutmak yaygın bir uygulamadır. &amp;ldquo;Deney&amp;rdquo; kelimesinin yalnızca akademik kullanımı belirtmek için tasarlanmadığını unutmayın, çünkü ticari ortamlarda bile makine öğrenimi genellikle deneysel olarak başlar.</description>
    </item>
    
    <item>
      <title>sınıflandırma</title>
      <link>https://www.wikiod.com/tr/scikit-learn/snflandrma/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/scikit-learn/snflandrma/</guid>
      <description>Rastgele OrmanSınıflandırıcı # Rastgele bir orman, veri kümesinin çeşitli alt örneklerinde bir dizi karar ağacı sınıflandırıcısına uyan ve tahmin doğruluğunu iyileştirmek ve aşırı uydurmayı kontrol etmek için ortalamayı kullanan bir meta tahmin edicidir.
Basit bir kullanım örneği:
İçe aktarmak:
from sklearn.ensemble import RandomForestClassifier Tren verilerini ve hedef verileri tanımlayın:
train = [[1,2,3],[2,5,1],[2,1,7]] target = [0,1,0] &amp;ldquo;Hedef&amp;rdquo; içindeki değerler, tahmin etmek istediğiniz etiketi temsil eder.
Bir RandomForest nesnesi başlatın ve öğrenme (sığdır) işlemini gerçekleştirin:</description>
    </item>
    
    <item>
      <title>Öznitelik Seçimi</title>
      <link>https://www.wikiod.com/tr/scikit-learn/oznitelik-secimi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/scikit-learn/oznitelik-secimi/</guid>
      <description>Düşük Varyans Özellik Kaldırma # Bu çok temel bir özellik seçme tekniğidir.
Temel fikri, bir özellik sabitse (yani 0 varyansa sahipse), o zaman herhangi bir ilginç desen bulmak için kullanılamayacağı ve veri kümesinden kaldırılabileceğidir.
Sonuç olarak, özellik elemeye yönelik buluşsal bir yaklaşım, ilk önce varyansı bir (düşük) eşiğin altında olan tüm özellikleri kaldırmaktır.
Belgelerdeki örnek ile başladığımızı varsayalım.
X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]] Burada her biri 6 örnek içeren 3 boole özelliği vardır.</description>
    </item>
    
    <item>
      <title>regresyon</title>
      <link>https://www.wikiod.com/tr/scikit-learn/regresyon/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/scikit-learn/regresyon/</guid>
      <description>Sıradan en küçük kareler # [Sıradan En Küçük Kareler] (https://en.wikipedia.org/wiki/Ordinary_least_squares) Aşağıdaki anlamda gözlemlenen sonuca en iyi uyan özelliklerin doğrusal kombinasyonunu bulmak için bir yöntem.
Tahmin edilecek sonuçların vektörü y ise ve açıklayıcı değişkenler X matrisini oluşturuyorsa, OLS β vektörünü çözerek bulacaktır.
minβ|y^ - y|22,
burada y^ = X β doğrusal tahmindir.
Sklearn&amp;rsquo;de bu, sklearn.linear_model.LinearRegression kullanılarak yapılır.
Uygulama İçeriği
OLS sadece regresyon problemlerine uygulanmalıdır, genellikle sınıflandırma problemleri için uygun değildir: Kontrast</description>
    </item>
    
    <item>
      <title>Boyut azaltma (Özellik seçimi)</title>
      <link>https://www.wikiod.com/tr/scikit-learn/boyut-azaltma-ozellik-secimi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/scikit-learn/boyut-azaltma-ozellik-secimi/</guid>
      <description>Temel Bileşen Analizi ile Boyutu Küçültme # Temel Bileşen Analizi özelliklerin doğrusal kombinasyonlarının dizilerini bulur. İlk doğrusal kombinasyon, özelliklerin varyansını maksimize eder (birim kısıtlamasına tabidir). Aşağıdaki lineer kombinasyonların her biri, önceki lineer kombinasyonların kapsadığı ortogonal alt uzaydaki özelliklerin varyansını maksimize eder.
Yaygın bir boyut küçültme tekniği, bu tür doğrusal kombinasyonların yalnızca k ilkini kullanmaktır. Özelliklerin n satır ve m sütundan oluşan bir X matrisi olduğunu varsayalım. İlk k doğrusal kombinasyonlar, m satır ve k sütundan oluşan bir βk matrisi oluşturur.</description>
    </item>
    
    <item>
      <title>Alıcı Çalışma Karakteristiği (ROC)</title>
      <link>https://www.wikiod.com/tr/scikit-learn/alc-calsma-karakteristigi-roc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.wikiod.com/tr/scikit-learn/alc-calsma-karakteristigi-roc/</guid>
      <description>ROC ve AUC&amp;rsquo;ye Giriş # Sınıflandırıcı çıktı kalitesini değerlendirmek için Alıcı Çalışma Karakteristiği (ROC) metriği örneği.
ROC eğrileri tipik olarak Y ekseninde gerçek pozitif oranı ve X ekseninde yanlış pozitif oranı gösterir. Bu, grafiğin sol üst köşesinin &amp;ldquo;ideal&amp;rdquo; nokta olduğu anlamına gelir - yanlış pozitif sıfır oranı ve gerçek pozitif oranı bir. Bu çok gerçekçi değildir, ancak eğrinin altındaki daha geniş bir alanın (AUC) genellikle daha iyi olduğu anlamına gelir.</description>
    </item>
    
  </channel>
</rss>
